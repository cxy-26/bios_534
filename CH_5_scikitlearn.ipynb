{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-Learn Package\n",
    "\n",
    "Steve Pittard wsp@emory.edu (citations to other sources are inline) \n",
    "\n",
    "By now you are probably fatigued with understanding the details of writing the code to split data, doing Cross Validation, storing the results, and looking at descriptive stats associated with the resulting RMSE. And this is all before considering the various parameters associated with whatever method we wish to implement.\n",
    "\n",
    "Each function has its own set of requirements which may not extend to other functions. What we need (well, what we would like) is a framework to streamline this process and automate it as much as possible but not at the expense of understanding the results.\n",
    "\n",
    "There is a module called [**scikit-learn**](https://scikit-learn.org/stable/) which can help make Machine learning a great deal easier by automating many activities that would otherwise be tedious and error prone. \n",
    "\n",
    "<img src=\"pics/scikit.png\" width =\"600\" height=600>\n",
    "\n",
    "From the project Github:\n",
    "\n",
    "> scikit-learn is a Python module for machine learning built on top of SciPy and is distributed under the 3-Clause BSD license. The project was started in 2007 by David Cournapeau as a Google Summer of Code project, and since then many volunteers have contributed. See the About us page for a list of core contributors.\n",
    "\n",
    "The scikit-lean learn module provides a uniform interface for calling different algorithms while simplifying the data splitting and calculation of various performance measures. It supports many different model types and also provides the ability to tune hyper parameters. Here are some of the features:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Classification:  SVM, nearest neighbors, random forest\n",
    "- Regression:  SVR, nearest neighbors, random forest\n",
    "- Clustering:  k-Means, spectral clustering, mean-shift\n",
    "- Preprocessing:  Transformation, scaling, feature extraction\n",
    "- Dimensionality Reduction:  k-Means, feature selection, non-negative matrix factorization\n",
    "- Model Selection:  Grid search, cross validation, metrics\n",
    "\n",
    "## Compared to R\n",
    "\n",
    "scikit-learn is not really a direct competitor to anything in R, at least in my opinion. R is a statistical framrwork first and formost which means that it has always had many statistical functions, and what we now consider to be Machine Learning methods, readily available. Over time, R has offered packages like [caret](http://topepo.github.io/caret/index.html), [tidymodels](https://www.tidymodels.org/), and [mlr](https://mlr.mlr-org.com/) (now deprecated), which represent either front ends to standalone ML packages or a rewrite of various methods. In this regard, R has had a big head start on Python. Keep in mind that data frames, which are a native object in R, are not native to Python and it was only when the Pandas module was created, that we could get similar capability. \n",
    "\n",
    "Moreover, there is a wealth of online support for these various packages which simplifies ML projects in R. There is an excellent book called [Applied Predictive](http://appliedpredictivemodeling.com/) Modeling which, though it uses the caret pacakge as a default framework, provides a great overview of general considerations relative to Machine Learning and Predictive Modeling. \n",
    "\n",
    "All this said, the scikit-learn module leverages the fact that Python was and is an easy-to-use general programming language. This makes Python a great language to develop and deploy models. The scikit-learn module is an attempt at a ground-up framework to provide ML capability. While there have been other such Python implementations, scikit-learn has the current \"mind share\" in this space. In my view, if you are going to do any type of Predictive Modeling or Machine Learning in Python then scikit-learn is the way to go.\n",
    "\n",
    "### Graphics\n",
    "\n",
    "I won't hide my opinion here that I think that R graphics, particularly ggplot2, is superior to Python graphics such as matplotlib and seaborn. (There is a reason that the [plotnine](https://towardsdatascience.com/how-to-use-ggplot2-in-python-74ab8adec129) package exists to give ggplot2 capability to Python users). However, if you are going to be working in the Python universe then you should spend time understanding matplotlib and seaborn because much of the documentation and support literature you will encounter will make reference to these frameworks. Also if you have a MATLAB background then you already have some experience with matplotlib. The scikit-learn package has a number of built-in plot types that are peculiar to various algorithms so before you try to produce a plot you might first check to see if something already exists before trying to make your own plots. \n",
    "\n",
    "## Putting scikit-learn to Work\n",
    "\n",
    "It’s easy to get lost in all that we have been doing up until this point so let’s review what the typical predictive modeling workflow will look like. \n",
    "\n",
    "   - Data Import (read in csv files, extractfrom a database, read from internet)\n",
    "   - Do some Data Visualization\n",
    "   - Data Prep (We haven’t done much of this just yet) \n",
    "  \n",
    "       * Find Missing Data and perform imputation \n",
    "       * Scaling \n",
    "       * Create dummy variables\n",
    "       * One hot encoding\n",
    "       * Dimensionality Reduction\n",
    "   \n",
    "   \n",
    "   - Data Splitting (training / test) \n",
    "   - Determine split ratio - K-Fold Cross Validation (repeated)\n",
    "   - Modeling / Prediction\n",
    "   - Evaluation\n",
    "   \n",
    "## Back To The Beginning\n",
    "\n",
    "It is implied that in predictive modeling the ultimate goal is to generate a model that could be reasonably applied to new data. As we have learned, it is best to train any model on a data set that has been (re)sampled in some way (e.g. K Fold CV) which should help provide a more realistic estimate of “out of sample” error.\n",
    "\n",
    "In our earliest example we tried to predict the MPG from mtcars using a basic linear modeling function. The sci-kit learn library provides a way to do this which allows us to easily substitute alternative functions without having to majorly change our code.\n",
    "\n",
    "As part of creating a model we can \"score\" the result using a specified performance measure. Before we do that, however, we’ll make a test / train pair. One way to do this is write our own functions to sample some proportion of a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the data frame is: 32\n",
      "Number of rows in training set: 25\n",
      "Number of rows in test set: 7\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/steviep42/bios534_spring_2020/master/data/mtcars.csv\"\n",
    "mtcars = pd.read_csv(url)\n",
    "\n",
    "# How many rows ?\n",
    "print(\"Number of rows in the data frame is:\",len(mtcars))\n",
    "\n",
    "# Let's sample 80% of the data into a training data set\n",
    "prop = int(.8*len(mtcars))\n",
    "train = mtcars[0:prop]\n",
    "print(\"Number of rows in training set:\", len(train))\n",
    "\n",
    "# Let's sample 20% of the data into a test data set\n",
    "test = mtcars[prop:prop+(len(mtcars)-prop)]\n",
    "print(\"Number of rows in test set:\", len(test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cyl</th>\n",
       "      <th>disp</th>\n",
       "      <th>hp</th>\n",
       "      <th>drat</th>\n",
       "      <th>wt</th>\n",
       "      <th>qsec</th>\n",
       "      <th>vs</th>\n",
       "      <th>am</th>\n",
       "      <th>gear</th>\n",
       "      <th>carb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>27.3</td>\n",
       "      <td>4</td>\n",
       "      <td>79.0</td>\n",
       "      <td>66</td>\n",
       "      <td>4.08</td>\n",
       "      <td>1.935</td>\n",
       "      <td>18.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120.3</td>\n",
       "      <td>91</td>\n",
       "      <td>4.43</td>\n",
       "      <td>2.140</td>\n",
       "      <td>16.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>30.4</td>\n",
       "      <td>4</td>\n",
       "      <td>95.1</td>\n",
       "      <td>113</td>\n",
       "      <td>3.77</td>\n",
       "      <td>1.513</td>\n",
       "      <td>16.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>15.8</td>\n",
       "      <td>8</td>\n",
       "      <td>351.0</td>\n",
       "      <td>264</td>\n",
       "      <td>4.22</td>\n",
       "      <td>3.170</td>\n",
       "      <td>14.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>19.7</td>\n",
       "      <td>6</td>\n",
       "      <td>145.0</td>\n",
       "      <td>175</td>\n",
       "      <td>3.62</td>\n",
       "      <td>2.770</td>\n",
       "      <td>15.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>301.0</td>\n",
       "      <td>335</td>\n",
       "      <td>3.54</td>\n",
       "      <td>3.570</td>\n",
       "      <td>14.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>21.4</td>\n",
       "      <td>4</td>\n",
       "      <td>121.0</td>\n",
       "      <td>109</td>\n",
       "      <td>4.11</td>\n",
       "      <td>2.780</td>\n",
       "      <td>18.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mpg  cyl   disp   hp  drat     wt  qsec  vs  am  gear  carb\n",
       "25  27.3    4   79.0   66  4.08  1.935  18.9   1   1     4     1\n",
       "26  26.0    4  120.3   91  4.43  2.140  16.7   0   1     5     2\n",
       "27  30.4    4   95.1  113  3.77  1.513  16.9   1   1     5     2\n",
       "28  15.8    8  351.0  264  4.22  3.170  14.5   0   1     5     4\n",
       "29  19.7    6  145.0  175  3.62  2.770  15.5   0   1     5     6\n",
       "30  15.0    8  301.0  335  3.54  3.570  14.6   0   1     5     8\n",
       "31  21.4    4  121.0  109  4.11  2.780  18.6   1   1     4     2"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a function to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of taining is: 25\n",
      "Length of test is: 7\n"
     ]
    }
   ],
   "source": [
    "def sampler(df=mtcars,prop=.80):\n",
    "    \n",
    "    # Let's sample 80% of the data into a training data set\n",
    "    prop = int(.8*len(df))\n",
    "    train = df[0:prop]\n",
    "   \n",
    "    # Let's sample 20% of the data into a test data set\n",
    "    test = df[prop:prop+(len(df)-prop)]\n",
    "    \n",
    "    return([train,test])\n",
    "\n",
    "train, test = sampler()\n",
    "print(\"Length of taining is:\",len(train))\n",
    "print(\"Length of test is:\",len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could actually write a helper function to do things like shuffle the data frame before we sample or specify whether to use boostrap sampling - if we wanted to. This winds up taking more work but gives us some generality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22, 12, 28, 11, 28, 0, 18, 13, 12, 11, 13, 24, 8, 27, 24, 23, 2, 28, 13, 3, 4, 25, 15, 28, 3, 19, 13, 23, 20, 8, 30, 6]\n"
     ]
    }
   ],
   "source": [
    "def shuffler(length=32, boot=False):\n",
    "    import random\n",
    "    randomList = []\n",
    "    done = False\n",
    "    \n",
    "    if (boot):\n",
    "        for ii in range(0,length):\n",
    "            randomList.append(random.randint(0,(length-1)))\n",
    "    else:\n",
    "        while not done:\n",
    "            mynum = random.randint(0,(length-1))\n",
    "            if (mynum not in randomList or len(randomList) < (length-1)):\n",
    "                randomList.append(mynum)\n",
    "            else:\n",
    "                done = True    \n",
    "    return(randomList)\n",
    "\n",
    "shuffledList = shuffler()\n",
    "print(shuffledList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of taining is: 25\n",
      "Length of test is: 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cyl</th>\n",
       "      <th>disp</th>\n",
       "      <th>hp</th>\n",
       "      <th>drat</th>\n",
       "      <th>wt</th>\n",
       "      <th>qsec</th>\n",
       "      <th>vs</th>\n",
       "      <th>am</th>\n",
       "      <th>gear</th>\n",
       "      <th>carb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>27.3</td>\n",
       "      <td>4</td>\n",
       "      <td>79.0</td>\n",
       "      <td>66</td>\n",
       "      <td>4.08</td>\n",
       "      <td>1.935</td>\n",
       "      <td>18.90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>19.7</td>\n",
       "      <td>6</td>\n",
       "      <td>145.0</td>\n",
       "      <td>175</td>\n",
       "      <td>3.62</td>\n",
       "      <td>2.770</td>\n",
       "      <td>15.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>19.2</td>\n",
       "      <td>8</td>\n",
       "      <td>400.0</td>\n",
       "      <td>175</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.845</td>\n",
       "      <td>17.05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>27.3</td>\n",
       "      <td>4</td>\n",
       "      <td>79.0</td>\n",
       "      <td>66</td>\n",
       "      <td>4.08</td>\n",
       "      <td>1.935</td>\n",
       "      <td>18.90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.7</td>\n",
       "      <td>8</td>\n",
       "      <td>360.0</td>\n",
       "      <td>175</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.440</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10.4</td>\n",
       "      <td>8</td>\n",
       "      <td>472.0</td>\n",
       "      <td>205</td>\n",
       "      <td>2.93</td>\n",
       "      <td>5.250</td>\n",
       "      <td>17.98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>21.4</td>\n",
       "      <td>4</td>\n",
       "      <td>121.0</td>\n",
       "      <td>109</td>\n",
       "      <td>4.11</td>\n",
       "      <td>2.780</td>\n",
       "      <td>18.60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mpg  cyl   disp   hp  drat     wt   qsec  vs  am  gear  carb\n",
       "25  27.3    4   79.0   66  4.08  1.935  18.90   1   1     4     1\n",
       "29  19.7    6  145.0  175  3.62  2.770  15.50   0   1     5     6\n",
       "24  19.2    8  400.0  175  3.08  3.845  17.05   0   0     3     2\n",
       "25  27.3    4   79.0   66  4.08  1.935  18.90   1   1     4     1\n",
       "4   18.7    8  360.0  175  3.15  3.440  17.02   0   0     3     2\n",
       "14  10.4    8  472.0  205  2.93  5.250  17.98   0   0     3     4\n",
       "31  21.4    4  121.0  109  4.11  2.780  18.60   1   1     4     2"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sampler(df=mtcars,prop=.80,shuffle=False,boot=False):\n",
    "    \n",
    "    if (shuffle,boot):\n",
    "        shuffledList = shuffler(len(df))\n",
    "        df = df.iloc[shuffledList]\n",
    "    \n",
    "    # Let's sample 80% of the data into a training data set\n",
    "    prop = int(.8*len(df))\n",
    "    train = df[0:prop]\n",
    "   \n",
    "    # Let's sample x% of the data into a test data set\n",
    "    test = df[prop:prop+(len(df)-prop)]\n",
    "    \n",
    "    return([train,test])\n",
    "\n",
    "train, test = sampler(prop=.8,boot=True)\n",
    "print(\"Length of taining is:\",len(train))\n",
    "print(\"Length of test is:\",len(test))\n",
    "\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Better Way\n",
    "\n",
    "So if you've been paying attention in the previous lectures you will remember that I had use a method called \"sample\" with respect to Pandas dataframes. So why would you write your own sampling functions when you have something better and easier at your disposal ? This is entirely true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cyl</th>\n",
       "      <th>disp</th>\n",
       "      <th>hp</th>\n",
       "      <th>drat</th>\n",
       "      <th>wt</th>\n",
       "      <th>qsec</th>\n",
       "      <th>vs</th>\n",
       "      <th>am</th>\n",
       "      <th>gear</th>\n",
       "      <th>carb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>160.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.875</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19.2</td>\n",
       "      <td>6</td>\n",
       "      <td>167.6</td>\n",
       "      <td>123</td>\n",
       "      <td>3.92</td>\n",
       "      <td>3.440</td>\n",
       "      <td>18.30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>33.9</td>\n",
       "      <td>4</td>\n",
       "      <td>71.1</td>\n",
       "      <td>65</td>\n",
       "      <td>4.22</td>\n",
       "      <td>1.835</td>\n",
       "      <td>19.90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22.8</td>\n",
       "      <td>4</td>\n",
       "      <td>140.8</td>\n",
       "      <td>95</td>\n",
       "      <td>3.92</td>\n",
       "      <td>3.150</td>\n",
       "      <td>22.90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>19.7</td>\n",
       "      <td>6</td>\n",
       "      <td>145.0</td>\n",
       "      <td>175</td>\n",
       "      <td>3.62</td>\n",
       "      <td>2.770</td>\n",
       "      <td>15.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mpg  cyl   disp   hp  drat     wt   qsec  vs  am  gear  carb\n",
       "1   21.0    6  160.0  110  3.90  2.875  17.02   0   1     4     4\n",
       "9   19.2    6  167.6  123  3.92  3.440  18.30   1   0     4     4\n",
       "19  33.9    4   71.1   65  4.22  1.835  19.90   1   1     4     1\n",
       "8   22.8    4  140.8   95  3.92  3.150  22.90   1   0     4     2\n",
       "29  19.7    6  145.0  175  3.62  2.770  15.50   0   1     5     6"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtcars.sample(n=len(mtcars)).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cyl</th>\n",
       "      <th>disp</th>\n",
       "      <th>hp</th>\n",
       "      <th>drat</th>\n",
       "      <th>wt</th>\n",
       "      <th>qsec</th>\n",
       "      <th>vs</th>\n",
       "      <th>am</th>\n",
       "      <th>gear</th>\n",
       "      <th>carb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>30.4</td>\n",
       "      <td>4</td>\n",
       "      <td>75.7</td>\n",
       "      <td>52</td>\n",
       "      <td>4.93</td>\n",
       "      <td>1.615</td>\n",
       "      <td>18.52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18.1</td>\n",
       "      <td>6</td>\n",
       "      <td>225.0</td>\n",
       "      <td>105</td>\n",
       "      <td>2.76</td>\n",
       "      <td>3.460</td>\n",
       "      <td>20.22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16.4</td>\n",
       "      <td>8</td>\n",
       "      <td>275.8</td>\n",
       "      <td>180</td>\n",
       "      <td>3.07</td>\n",
       "      <td>4.070</td>\n",
       "      <td>17.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16.4</td>\n",
       "      <td>8</td>\n",
       "      <td>275.8</td>\n",
       "      <td>180</td>\n",
       "      <td>3.07</td>\n",
       "      <td>4.070</td>\n",
       "      <td>17.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>32.4</td>\n",
       "      <td>4</td>\n",
       "      <td>78.7</td>\n",
       "      <td>66</td>\n",
       "      <td>4.08</td>\n",
       "      <td>2.200</td>\n",
       "      <td>19.47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10.4</td>\n",
       "      <td>8</td>\n",
       "      <td>460.0</td>\n",
       "      <td>215</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.424</td>\n",
       "      <td>17.82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.4</td>\n",
       "      <td>6</td>\n",
       "      <td>258.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.215</td>\n",
       "      <td>19.44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19.2</td>\n",
       "      <td>6</td>\n",
       "      <td>167.6</td>\n",
       "      <td>123</td>\n",
       "      <td>3.92</td>\n",
       "      <td>3.440</td>\n",
       "      <td>18.30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>14.7</td>\n",
       "      <td>8</td>\n",
       "      <td>440.0</td>\n",
       "      <td>230</td>\n",
       "      <td>3.23</td>\n",
       "      <td>5.345</td>\n",
       "      <td>17.42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>15.5</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150</td>\n",
       "      <td>2.76</td>\n",
       "      <td>3.520</td>\n",
       "      <td>16.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mpg  cyl   disp   hp  drat     wt   qsec  vs  am  gear  carb\n",
       "18  30.4    4   75.7   52  4.93  1.615  18.52   1   1     4     2\n",
       "5   18.1    6  225.0  105  2.76  3.460  20.22   1   0     3     1\n",
       "11  16.4    8  275.8  180  3.07  4.070  17.40   0   0     3     3\n",
       "11  16.4    8  275.8  180  3.07  4.070  17.40   0   0     3     3\n",
       "17  32.4    4   78.7   66  4.08  2.200  19.47   1   1     4     1\n",
       "15  10.4    8  460.0  215  3.00  5.424  17.82   0   0     3     4\n",
       "3   21.4    6  258.0  110  3.08  3.215  19.44   1   0     3     1\n",
       "9   19.2    6  167.6  123  3.92  3.440  18.30   1   0     4     4\n",
       "16  14.7    8  440.0  230  3.23  5.345  17.42   0   0     3     4\n",
       "21  15.5    8  318.0  150  2.76  3.520  16.87   0   0     3     2"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def newsampler(df=mtcars,boot=False,prop=.8):\n",
    "    \n",
    "    if (boot):    \n",
    "        df = df.sample(n=len(df),replace=True)\n",
    "    else:\n",
    "        df = df.sample(n=len(df))\n",
    "    \n",
    "    # Let's sample prop% of the data into a training data set\n",
    "    prop = int(prop*len(df))\n",
    "    train = df[0:prop]\n",
    "   \n",
    "    # Let's sample the rest of the data into a test data set\n",
    "    test = df[prop:prop+(len(df)-prop)]\n",
    "    \n",
    "    return([train,test])\n",
    "\n",
    "train, test = newsampler(prop=.7,boot=True)\n",
    "test\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we could now use this to model the training data and later apply it to the test data. We explored this last time when we were using regression to predict outcomes on the fuel economy of the cars within the mtcars data frame. Remember that our performance metric is the RMSE (Root Mean Square Error) which is a very common metric for judging regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 2.875\n",
      "Test RMSE: 3.355\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm \n",
    "train, test = newsampler()\n",
    "\n",
    "# We define our own rmse function though scikit has some\n",
    "# functions that might simplify this but it does't matter\n",
    "\n",
    "def rmse(actual,predictions):\n",
    "   from math import sqrt\n",
    "   myrmse = sqrt(((predictions-actual)**2).mean())\n",
    "   return round(myrmse,3)\n",
    "\n",
    "# Do regression and figure out rmse for training \n",
    "    \n",
    "result = sm.OLS(train.mpg,sm.add_constant(train.wt)).fit()\n",
    "train_rmse = rmse(train.mpg,result.predict(sm.add_constant(train.wt)))\n",
    "print(\"Train RMSE:\", train_rmse)\n",
    "\n",
    "test_rmse  = rmse(test.mpg,result.predict(sm.add_constant(test.wt)))\n",
    "print(\"Test RMSE:\", test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit to The Rescue\n",
    "\n",
    "So we wrote a function to sample some proportion of a data frame to create a training data set and to also have a test data set comprised of the remaining data. Common training and test proportions include 80 / 20, 70 / 30, and 60 / 40. We didn't really need to write a function as the scikit-learn package has a function that will us do this. We'll also introduce a convention used in Python Machine Learning where we split the label (what is being predicted) into a separate structure. \n",
    "\n",
    "The remaining information represents the predictor variable(s). In the parlance of the Python, we refer to the former as \"y\" (lower case) and the latter as \"X\" (upper case). We do this in large part because there is a helper function called **train_test_split** which expects this format to do its work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Let's set up some simple example data - nothing complicated\n",
    "X = np.arange(12)\n",
    "y = range(6)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1],\n",
       "       [ 2,  3],\n",
       "       [ 4,  5],\n",
       "       [ 6,  7],\n",
       "       [ 8,  9],\n",
       "       [10, 11]])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's reshape predictions to be a matrix\n",
    "X = X.reshape(6,2)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20) \n",
    "                                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10 11]\n",
      " [ 2  3]\n",
      " [ 4  5]\n",
      " [ 6  7]]\n",
      "\n",
      "[5, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "# Look at the training data\n",
    "print(X_train)\n",
    "print()\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8 9]\n",
      " [0 1]]\n",
      "\n",
      "[4, 0]\n"
     ]
    }
   ],
   "source": [
    "# Look at the test data\n",
    "print(X_test)\n",
    "print()\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course we can now look at one of previous examples and factor in the train_test_split function. We also learn how scikit-learn likes to return data. Note that while we do not have to use the variable names X_train, X_test and so on, this is something of a convention you will see heavily used in the community. This is why I stick with it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of X_train: (25, 10)\n",
      "Dimensions of X_test (7, 10)\n",
      "Train and Test RMSE are: (2.934, 3.302)\n"
     ]
    }
   ],
   "source": [
    "# Separate our dataframe into an X, y pair\n",
    "y = mtcars.mpg\n",
    "X = mtcars.drop('mpg',axis=1)\n",
    "\n",
    "# Next we create a training and test pair with 80 / 20 proportions\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "print(\"Dimensions of X_train:\", X_train.shape)\n",
    "print(\"Dimensions of X_test\", X_test.shape)\n",
    "\n",
    "X_train.head()\n",
    "\n",
    "# Generate the OLD model using the trainining data\n",
    "result = sm.OLS(y_train,sm.add_constant(X_train.wt)).fit()\n",
    "\n",
    "# Compute the training error\n",
    "train_rmse = rmse(y_train,result.predict(sm.add_constant(X_train.wt)))\n",
    "\n",
    "# Now compute the testing error\n",
    "test_rmse  = rmse(y_test,result.predict(sm.add_constant(X_test.wt)))\n",
    "\n",
    "# What do we have ? \n",
    "print(\"Train and Test RMSE are:\",(train_rmse, test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this is helpful in that we don't need to write our own sampler function. In fact, if you look for examples on Google you will rarely see situations wherein someone created their own sample function although it is not a bad thing to do. It's just that the ML community prefers to leverage what scikit-learn has to offer so you will see the **train_test_split** function used extensively. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, running one iteration on a train / test pair isn't very useful. We already discovered that K-fold cross validation is a technique to split up a data set into K-folds and systematically build training sets out of the combined K-1 folds while use the \"holdout\" fold as a test data set at some point in the process. \n",
    "\n",
    "This helps address situations wherein large variation due to outliers might be present in one fold but not another. the ultimatel goal is to build a model on a number of training data sets with the hopes that we can better predict model performance on unseen data. Here were use a helper function called **KFold**. The function handles the chopping of the data for us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=3, random_state=None, shuffle=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=3)\n",
    "print(kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   gene1  gene2\n",
      "0    0.3   0.10\n",
      "1    0.9   0.35\n",
      "2    0.7   0.20\n",
      "3    0.4   0.88\n",
      "4    0.3   0.50\n",
      "5    0.5   0.40\n",
      "\n",
      "0    1\n",
      "1    0\n",
      "2    0\n",
      "3    1\n",
      "4    0\n",
      "5    1\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Let's set up some simple example data - nothing complicated\n",
    "d = {'gene1': [.3, .9, .7, .4, .3, .5], 'gene2': [.10, .35, .2, .88, .5, .4], 'target': [1, 0, 0 ,1, 0, 1]}\n",
    "mydf = pd.DataFrame(d)\n",
    "\n",
    "y = mydf.target\n",
    "X = mydf.drop('target',axis=1)\n",
    "\n",
    "print(X)\n",
    "print()\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf.get_n_splits(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [2 3 4 5] TEST: [0 1]\n",
      "TRAIN: [0 1 4 5] TEST: [2 3]\n",
      "TRAIN: [0 1 2 3] TEST: [4 5]\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf.split(X):\n",
    "    \n",
    "    # This prints out the indices NOT the actual values\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [2 3 4 5] TEST: [0 1]\n",
      "   gene1  gene2\n",
      "2    0.7   0.20\n",
      "3    0.4   0.88\n",
      "4    0.3   0.50\n",
      "5    0.5   0.40\n",
      "\n",
      "TRAIN: [0 1 4 5] TEST: [2 3]\n",
      "   gene1  gene2\n",
      "0    0.3   0.10\n",
      "1    0.9   0.35\n",
      "4    0.3   0.50\n",
      "5    0.5   0.40\n",
      "\n",
      "TRAIN: [0 1 2 3] TEST: [4 5]\n",
      "   gene1  gene2\n",
      "0    0.3   0.10\n",
      "1    0.9   0.35\n",
      "2    0.7   0.20\n",
      "3    0.4   0.88\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf.split(X):\n",
    "    \n",
    "    # This prints out the indices NOT the actual values\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    print(X_train)\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we could try this out with our familiar mtcars dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of folds: 4\n"
     ]
    }
   ],
   "source": [
    "# Split \n",
    "kf = KFold(n_splits=4)\n",
    "print(\"Number of folds:\", kf.get_n_splits(mtcars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we can look at the indices generated by **KFold**. We can then train our model on each of the \"combined\" folds and then apply it to the test fold. In this case we have 4 folds but we could experiment with various numbers. Our data isn't that large so we won't do that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31] TEST: [0 1 2 3 4 5 6 7]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31] TEST: [ 8  9 10 11 12 13 14 15]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 24 25 26 27 28 29 30 31] TEST: [16 17 18 19 20 21 22 23]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23] TEST: [24 25 26 27 28 29 30 31]\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf.split(mtcars):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fold_number  train   test\n",
      "0            0  3.110  2.440\n",
      "1            1  3.277  1.879\n",
      "2            2  2.070  4.821\n",
      "3            3  3.087  2.571\n"
     ]
    }
   ],
   "source": [
    "def rmse(actual,predictions):\n",
    "   from math import sqrt\n",
    "   myrmse = sqrt(((predictions-actual)**2).mean())\n",
    "   return round(myrmse,3)\n",
    "\n",
    "X = mtcars.drop('mpg',axis=1)\n",
    "y = mtcars.mpg\n",
    "\n",
    "scores = []\n",
    "\n",
    "for fold_number, (train_index, test_index) in enumerate(kf.split(mtcars)):\n",
    "\n",
    "    # Do regression and figure out rmse for training and test\n",
    "    \n",
    "    X_train, X_test = mtcars.iloc[train_index], mtcars.iloc[test_index]\n",
    "\n",
    "    result = sm.OLS(X_train.mpg,sm.add_constant(X_train.wt)).fit()\n",
    "    train_rmse = rmse(X_train.mpg,result.predict(sm.add_constant(X_train.wt)))\n",
    "    test_rmse  = rmse(X_test.mpg,result.predict(sm.add_constant(X_test.wt)))\n",
    "    \n",
    "    scores.append([fold_number,train_rmse,test_rmse])\n",
    "    \n",
    "rmse_errors = pd.DataFrame(scores,columns=['fold_number','train','test'])\n",
    "print(rmse_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fold_number    1.50000\n",
       "train          2.88600\n",
       "test           2.92775\n",
       "dtype: float64"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.mean(rmse_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold_number</th>\n",
       "      <th>train_rmse</th>\n",
       "      <th>test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.885866</td>\n",
       "      <td>2.927868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.290994</td>\n",
       "      <td>0.550220</td>\n",
       "      <td>1.297341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.070390</td>\n",
       "      <td>1.879322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>2.832523</td>\n",
       "      <td>2.299767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.500000</td>\n",
       "      <td>3.098120</td>\n",
       "      <td>2.505508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.250000</td>\n",
       "      <td>3.151464</td>\n",
       "      <td>3.133608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.276833</td>\n",
       "      <td>4.821133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fold_number  train_rmse  test_rmse\n",
       "count     4.000000    4.000000   4.000000\n",
       "mean      1.500000    2.885866   2.927868\n",
       "std       1.290994    0.550220   1.297341\n",
       "min       0.000000    2.070390   1.879322\n",
       "25%       0.750000    2.832523   2.299767\n",
       "50%       1.500000    3.098120   2.505508\n",
       "75%       2.250000    3.151464   3.133608\n",
       "max       3.000000    3.276833   4.821133"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_errors.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Better\n",
    "\n",
    "So this nice in that the **KFolds** function does the chopping up of the data for us. We don't have to write our own function. One thing that the Machine Learning does when using Python is to separate what is being predicted, in this case the **mpg** variable, from the data being used to make the prediction. One typically uses the nomenclature of **y** (lower case) to refer to the former and **X** (upper case) to refer to the latter. Note that while this isn't strictly necessary, at least as far as I can determine, it is a popular convention. So I'll just rewrite what we have above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fold_number  train   test\n",
      "0            0  2.931  3.308\n",
      "1            1  2.920  3.217\n",
      "2            2  2.727  3.560\n",
      "3            3  3.058  2.672\n"
     ]
    }
   ],
   "source": [
    "def rmse(actual,predictions):\n",
    "   from math import sqrt\n",
    "   myrmse = sqrt(((predictions-actual)**2).mean())\n",
    "   return round(myrmse,3)\n",
    "\n",
    "X = mtcars.drop('mpg',axis=1)\n",
    "y = mtcars.mpg\n",
    "\n",
    "scores = []\n",
    "import statsmodels.api as sm\n",
    "for fold_number, (train_index, test_index) in enumerate(kf.split(mtcars)):\n",
    "    \n",
    "    ## Get Training Matrix and Vector\n",
    "\n",
    "    X_train = X.iloc[train_index]\n",
    "    y_train = y[train_index]\n",
    "\n",
    "    ## Get Testing Matrix Values\n",
    "\n",
    "    X_test = X.iloc[test_index]\n",
    "    y_test = y.iloc[test_index]\n",
    "\n",
    "    result = sm.OLS(y_train,sm.add_constant(X_train.wt)).fit()\n",
    "    train_rmse = rmse(y_train,result.predict(sm.add_constant(X_train.wt)))\n",
    "    test_rmse  = rmse(y_test,result.predict(sm.add_constant(X_test.wt)))\n",
    "    \n",
    "    scores.append([fold_number,train_rmse,test_rmse])\n",
    "    \n",
    "rmse_errors = pd.DataFrame(scores,columns=['fold_number','train','test'])\n",
    "print(rmse_errors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also understand that there are performance metrics available to using the **sklearn.metrics** functions to help us. We can get the Mean Squared Error and then take the square root of that to obtain the RMSE / Root Mean Squared Error.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fold_number     train      test\n",
      "0            0  2.864151  4.084597\n",
      "1            1  2.800365  3.493108\n",
      "2            2  3.030732  2.692178\n",
      "3            3  2.849638  3.257030\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X = mtcars.drop('mpg',axis=1)\n",
    "y = mtcars.mpg\n",
    "\n",
    "scores = []\n",
    "import statsmodels.api as sm\n",
    "for fold_number, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    \n",
    "    ## Get Training Matrix and Vector\n",
    "\n",
    "    X_train = X.iloc[train_index]\n",
    "    y_train = y[train_index]\n",
    "\n",
    "    ## Get Testing Matrix Values\n",
    "\n",
    "    X_test = X.iloc[test_index]\n",
    "    y_test = y.iloc[test_index]\n",
    "\n",
    "    \n",
    "#   X_train, X_test = mtcars.iloc[train_index], mtcars.iloc[test_index]\n",
    "\n",
    "    result    = sm.OLS(y_train,sm.add_constant(X_train.wt)).fit()\n",
    "    train_mse = mean_squared_error(y_train,result.predict(sm.add_constant(X_train.wt)))\n",
    "    test_mse  = mean_squared_error(y_test,result.predict(sm.add_constant(X_test.wt)))\n",
    "    \n",
    "    train_rmse = train_mse**0.5\n",
    "    test_rmse  = test_mse**0.5\n",
    "    \n",
    "    scores.append([fold_number,train_rmse,test_rmse])\n",
    "    \n",
    "rmse_errors = pd.DataFrame(scores,columns=['fold_number','train','test'])\n",
    "print(rmse_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "\n",
    "So it turns out that scikit-learn has its own methods for Linear Regression that include various options such as to use Ridge or Lasso. We'll now replace the simple OLS method with something from scikit-learn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fold_number  train_rmse  test_rmse\n",
      "0            0    3.109674   2.439916\n",
      "1            1    3.276833   1.879322\n",
      "2            2    2.070390   4.821133\n",
      "3            3    3.086567   2.571099\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "X = mtcars.wt\n",
    "y = mtcars.mpg\n",
    "\n",
    "kf = KFold(n_splits=4)\n",
    "\n",
    "scores = []\n",
    "\n",
    "for fold_number, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    \n",
    "    ## Get Training Matrix and Vector\n",
    "\n",
    "    X_train = X.iloc[train_index]\n",
    "    y_train = y[train_index].values.reshape(-1,1)\n",
    "\n",
    "    ## Get Testing Matrix Values\n",
    "\n",
    "    X_test = X.iloc[test_index]\n",
    "    y_test = y.iloc[test_index].values.reshape(-1,1)\n",
    "\n",
    "    model = LinearRegression()\n",
    "    \n",
    "    # All scikit model methods (aka 'estimators') have specific methods\n",
    "    # such as predict and fit\n",
    "    \n",
    "    reg = model.fit(X_train.values.reshape(-1,1),y_train)\n",
    "    \n",
    "    y_train_preds = model.predict(X_train.values.reshape(-1,1))\n",
    "    y_test_preds = model.predict(X_test.values.reshape(-1,1))\n",
    "     \n",
    "    train_mse = mean_squared_error(y_train,y_train_preds)\n",
    "    test_mse  = mean_squared_error(y_test,y_test_preds)\n",
    "    \n",
    "    train_rmse = math.sqrt(train_mse)\n",
    "    test_rmse = math.sqrt(test_mse)\n",
    "    \n",
    "    scores.append([fold_number,train_rmse,test_rmse])\n",
    "    \n",
    "rmse_errors = pd.DataFrame(scores,columns=['fold_number','train_rmse','test_rmse'])\n",
    "print(rmse_errors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The thing with scikit-learn functions is that they want input in a particular format so some type of conversion is ususally required which is why you saw things like the **X_test.values.reshape(-1,1)** statement above. Sometimes it's easier to convert the pandas data frame into an array. In this example, we'll do just the regression piece:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression equation coefficients:\n",
      " [-0.16881263  0.01623358 -0.02424055  0.70590083 -4.03214213  0.86828517\n",
      "  0.36470431  2.55092849  0.50293618]\n",
      "\n",
      "Regression equation intercept: 12.83083549213168\n",
      "Root Mean squared error: 2.15\n",
      "Coefficient of determination: 0.87\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/steviep42/bios534_spring_2020/master/data/mtcars.csv\"\n",
    "mtcars = pd.read_csv(url)\n",
    "\n",
    "mtvals = mtcars.values            # creates a numpy array\n",
    "type(mtvals)                      # Observe the data type\n",
    "\n",
    "y = mtvals[:,0]         # Gets the mpg column\n",
    "X = mtvals[:,1:10]      # Gets everything BUT the mpg column\n",
    "\n",
    "# Setup a new model\n",
    "model = LinearRegression()\n",
    "\n",
    "# fit the model\n",
    "reg = model.fit(X,y)\n",
    "\n",
    "# Look at the equation coeeficients \n",
    "print(\"Regression equation coefficients:\\n\", reg.coef_)\n",
    "\n",
    "# Look at the intercept\n",
    "print(\"\\nRegression equation intercept:\",reg.intercept_)\n",
    "\n",
    "# Do a prediction\n",
    "y_preds = reg.predict(X)\n",
    "\n",
    "# Get mean sqaured error\n",
    "print('Root Mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error(y, y_preds)))\n",
    "\n",
    "# Get R^2\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It might be helpful to know that most models have a default score method that defaults to something that makes sense for the method being used. In the case of regression, the default scoring metric is the R^2 value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(X,y).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Small Review\n",
    "\n",
    "So now want to clean all of this up into something that can serve as an example for your future work. Things are kind of messy right now so let's review what it is we would generally want to do:\n",
    "\n",
    "1. Split a data frame into what is being predicted vs the predictor variables\n",
    "2. Use the training data as a source against which to do the cross fold valiation\n",
    "3. For each fold, apply whatever model you want (e.g. Linear Regression) and capture metrics\n",
    "4. Look at the performance metric(s) (e.g. RMSE) across each fold or in aggregate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to do this is write a function that implements the above. It's not hard to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE for loop 0 is: 2.228744351236648\n",
      "Test RMSE for loop 0 is: 2.6663572813751095 \n",
      "\n",
      "Training RMSE for loop 1 is: 1.159701374516322\n",
      "Test RMSE for loop 1 is: 4.317008703583661 \n",
      "\n",
      "Training RMSE for loop 2 is: 2.099984576068435\n",
      "Test RMSE for loop 2 is: 3.2158664154053187 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ii = 0\n",
    "url = \"https://raw.githubusercontent.com/steviep42/bios534_spring_2020/master/data/mtcars.csv\"\n",
    "mtcars = pd.read_csv(url)\n",
    "\n",
    "rmse_train_info = []\n",
    "rmse_test_info = []\n",
    "\n",
    "mtvals = mtcars.values            # creates a numpy array\n",
    "\n",
    "y = mtvals[:,0]         # Gets the mpg column\n",
    "X = mtvals[:,1:10]      # Gets everything BUT the mpg column\n",
    "\n",
    "kfold = KFold(3)\n",
    "\n",
    "# Main processing loop for the folds\n",
    "\n",
    "for train_index, test_index in kfold.split(X, y):\n",
    "  # split data coming from each of the 4 folds\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        Y_train, Y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Initialize a model\n",
    "        regress = LinearRegression()\n",
    "        \n",
    "        # Fit the Model\n",
    "        regress.fit(X_train,Y_train)\n",
    "        \n",
    "        # Predict the target on the training dataset\n",
    "        predict_train = regress.predict(X_train)\n",
    "  \n",
    "        # Root Mean Squared Error on training dataset\n",
    "        rmse_train = mean_squared_error(Y_train,predict_train)**(0.5)\n",
    "        print(\"Training RMSE for loop\",ii,\"is:\", rmse_train)\n",
    "       \n",
    "        # Append the rmse to the rmse_train_info vector\n",
    "        rmse_train_info.append(rmse_train)\n",
    "        \n",
    "        # Now let's do a prediction on the test data\n",
    "        predict_test = regress.predict(X_test)\n",
    "        \n",
    "        # Root Mean Squared Error on training dataset\n",
    "        rmse_test = mean_squared_error(Y_test,predict_test)**(0.5)\n",
    "        print(\"Test RMSE for loop\",ii,\"is:\", rmse_test,\"\\n\")\n",
    "       \n",
    "        # Append the rmse to the rmse_test_info vector\n",
    "        rmse_test_info.append(rmse_test)\n",
    "\n",
    "        ii = ii+1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Easier Cross Validation\n",
    "\n",
    "Or, we could look at what scikit-learn can do for us. The following introduces the  **cross_val_score** and **cross_validate** functions which provide a wrapper around a given **kfolds** object while also applying a predefined scoring method. While this approach results in less code it also provides less transparency. So what we do here is:\n",
    "\n",
    "  - Create a Model object (e.g. Regression)\n",
    "  - Specify one or more scoring metrics\n",
    "  - Create a KFold object with at least two folds\n",
    "  - Pass the above information to the cross_validate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE per fold: [2.78732274 3.83729498 5.03527484 3.26172188]\n",
      "Mean Test RMSE: 3.73\n",
      "Mean Train RMSE: 1.87\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "mtvals = mtcars.values  # Create an array version of the data\n",
    "y = mtvals[:,0]         # Gets the mpg column\n",
    "X = mtvals[:,1:10]      # Gets everything BUT the mpg column\n",
    "\n",
    "# Setup the model \n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "# We have to designate a scoring metric \n",
    "mse = make_scorer(mean_squared_error)\n",
    "\n",
    "# Set up some folds\n",
    "kfold = KFold(n_splits=4)\n",
    "\n",
    "# The cross_validate function handles the execution of the model\n",
    "# as well as the management of the folds\n",
    "\n",
    "cv  = cross_validate(model,X,y,scoring=(mse), cv=kfold, return_train_score=True)\n",
    "\n",
    "# Here we print out the rmse of the test / holdout data\n",
    "print(\"Test RMSE per fold:\",(cv['test_score']**0.5))\n",
    "\n",
    "# Look at the mean of this RMSE array\n",
    "print(\"Mean Test RMSE:\",(cv['test_score']**0.5).mean().round(2))\n",
    "\n",
    "# Look at the mean of this RMSE array\n",
    "print(\"Mean Train RMSE:\",(cv['train_score']**0.5).mean().round(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A nice side effect of using the scikit approach is that we can easily substitute in other methods as long as they make sense of course. In other words, since we are predicting a continuous outcome we need to select a method that supports this intent. Let's try Ridge regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE per fold: [2.33626326 2.9428611  4.59536042 2.57621531]\n",
      "Mean Test RMSE: 3.11\n",
      "Mean Train RMSE: 1.97\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.linear_model import Ridge\n",
    "    \n",
    "# Setup the model \n",
    "\n",
    "model = Ridge()\n",
    "\n",
    "# We have to designate a scoring metric \n",
    "mse = make_scorer(mean_squared_error)\n",
    "\n",
    "# Set up some folds\n",
    "kfold = KFold(n_splits=4)\n",
    "\n",
    "# The cross_validate function handles the execution of the model\n",
    "# as well as the management of the folds\n",
    "\n",
    "cv  = cross_validate(model,X,y,scoring=(mse), cv=kfold, return_train_score=True)\n",
    "\n",
    "# Here we print out the rmse of the test / holdout data\n",
    "print(\"Test RMSE per fold:\",(cv['test_score']**0.5))\n",
    "\n",
    "# Look at the mean of this RMSE array\n",
    "print(\"Mean Test RMSE:\",(cv['test_score']**0.5).mean().round(2))\n",
    "\n",
    "# Look at the mean of this RMSE array\n",
    "print(\"Mean Train RMSE:\",(cv['train_score']**0.5).mean().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could always use Repeated Cross Fold Validation. This is fairly straightforward but you have to know what function to call. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE per fold: [4.47752136 2.44282638 2.84717458 2.64975775 2.8450318  2.52470336\n",
      " 3.3578655  2.98819652 1.87052263]\n",
      "Mean Test RMSE: 2.89\n",
      "Mean Train RMSE: 2.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "model = Ridge()\n",
    "\n",
    "# We have to designate a scoring metric \n",
    "mse = make_scorer(mean_squared_error)\n",
    "\n",
    "# Set up some folds\n",
    "repeat_kfold = RepeatedKFold(n_splits=3, n_repeats=3, random_state=1)\n",
    "\n",
    "# The cross_validate function handles the execution of the model\n",
    "# as well as the management of the folds\n",
    "\n",
    "cv  = cross_validate(model,X,y,scoring=(mse), cv=repeat_kfold, return_train_score=True)\n",
    "\n",
    "# Here we print out the rmse of the test / holdout data\n",
    "print(\"Test RMSE per fold:\",(cv['test_score']**0.5))\n",
    "\n",
    "# Look at the mean of this RMSE array\n",
    "print(\"Mean Test RMSE:\",(cv['test_score']**0.5).mean().round(2))\n",
    "\n",
    "# Look at the mean of this RMSE array\n",
    "print(\"Mean Train RMSE:\",(cv['train_score']**0.5).mean().round(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it is important to know that there are a number of built in scoring metrics available for regression and classification. These are available to assist with the evaluation of any models that you make and could simplify your work. Check the [reference](https://scikit-learn.org/stable/modules/model_evaluation.html) page for a more detailed discussion of such metrics. \n",
    "\n",
    "<img src=\"pics/rm.png\" width =\"600\" height=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE per fold: [4.47752136 2.44282638 2.84717458 2.64975775 2.8450318  2.52470336\n",
      " 3.3578655  2.98819652 1.87052263]\n",
      "Test R2 per fold: [0.69985352 0.62492573 0.34826034 0.79611432 0.80087933 0.74496963\n",
      " 0.66057129 0.75612977 0.89198932]\n"
     ]
    }
   ],
   "source": [
    "model = Ridge()\n",
    "\n",
    "# These metrics are known to scikit\n",
    "scoring = {'neg_mean_squared_error': 'neg_mean_squared_error',\n",
    "           'r2':'r2'}\n",
    "\n",
    "# Set up some folds\n",
    "repeat_kfold = RepeatedKFold(n_splits=3, n_repeats=3, random_state=1)\n",
    "\n",
    "# The cross_validate function handles the execution of the model\n",
    "# as well as the management of the folds\n",
    "\n",
    "cv  = cross_validate(model,\n",
    "                     X,y,\n",
    "                     scoring=scoring, \n",
    "                     cv=repeat_kfold, \n",
    "                     return_train_score=True)\n",
    "\n",
    "# Here we print out the rmse of the test / holdout data\n",
    "print(\"Test RMSE per fold:\",np.sqrt(np.abs(cv['test_neg_mean_squared_error'])))\n",
    "\n",
    "# Here we print out the r2of the test / holdout data\n",
    "print(\"Test R2 per fold:\",cv['test_r2'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparamaters\n",
    "\n",
    "Linear Regression is straighforward and there aren't many arguments to supply to the function although there are a couple of “hyperparameters” which are arguments to a given method that you can set before you call the method. In this case there are two hyperparameters called \"alpha\" and \"solver\" that assume default variables if we don’t supply values. There is even a function called **RidgeCV** which will handle some of this stuff for us although it is specific to the **Ridge** method. Here is how we could use it to find the best value for **alpha**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RidgeCV RMSE: 3.371\n",
      "RidgeCV Best Alpha: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "cv = RepeatedKFold(n_splits=3, n_repeats=3, random_state=1)\n",
    "\n",
    "# We have to designate a scoring metric \n",
    "mse = make_scorer(mean_squared_error)\n",
    "\n",
    "# define search\n",
    "search = RidgeCV(alphas=np.arange(0, 1, 0.1), cv=cv, scoring=(mse))\n",
    "\n",
    "# perform the search\n",
    "results_ridge = search.fit(X, y)\n",
    "\n",
    "print('RidgeCV RMSE: %.3f' % results_ridge.best_score_**0.5)\n",
    "print('RidgeCV Best Alpha: %s' % results_ridge.alpha_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also call a more general function to handle the search for an ideal set of parameters in relation to optimizing target metric. If our desired score is to minimize the RMSE then we can indicate this in the scoring paramter. We can also provide a parameter grid with values we want to be evaluated as part of this optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid_Search RMSE: 3.371\n",
      "Grid_Search Config: {'alpha': 0.0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# create model\n",
    "model = Ridge()\n",
    "\n",
    "# Create a grid of parameters to be evaluated. Note that\n",
    "# this is specific to the method being used\n",
    "param_grid={'alpha': np.arange(0,1,0.1)}\n",
    "\n",
    "# do the grid search\n",
    "search = GridSearchCV(model, param_grid, scoring=(mse), cv=cv, n_jobs=-1)\n",
    "\n",
    "# Get the results\n",
    "results_gridsearch = search.fit(X, y)\n",
    "\n",
    "# summarize\n",
    "print('Grid_Search RMSE: %.3f' % results_gridsearch.best_score_**0.5)\n",
    "print('Grid_Search Config: %s' % results_gridsearch.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid_Search RMSE: 3.371\n",
      "Grid_Search Best Parameter Config: {'alpha': 0.0, 'solver': 'svd'}\n"
     ]
    }
   ],
   "source": [
    "# Let's expand the parameter dictionary to include \"solver\"\n",
    "\n",
    "model = Ridge()\n",
    "\n",
    "# Here we add in additional parameters into the grid\n",
    "param_grid={'alpha': np.arange(0,1,0.1),\n",
    "            'solver': ['svd', 'cholesky', 'lsqr']}\n",
    "\n",
    "search = GridSearchCV(model, param_grid, scoring=(mse), cv=cv, n_jobs=-1)\n",
    "\n",
    "# perform the search\n",
    "results_gridsearch = search.fit(X, y)\n",
    "\n",
    "# summarize\n",
    "print('Grid_Search RMSE: %.3f' % results_gridsearch.best_score_**0.5)\n",
    "print('Grid_Search Best Parameter Config: %s' % results_gridsearch.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6756580632280433"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_mod.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Null Model\n",
    "\n",
    "Keep in mind that we are assuming that whatever we are doing (or plan to do) is better than doing little or nothing. That is, we could just make our model reflect the average MPG of the training data and leave it at that. After all, why go to the trouble of writing code and testing out different methods if we could do just as well by going with the average MPG approach. scikit-learn has what is known as a \"dummy\" model function that can implement this \"method\". First, check out this graph which shows us how the Null model might look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Null Model - Mean MPG')"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEICAYAAABGaK+TAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAZ+0lEQVR4nO3df5Bd5X3f8fdH68Vas4wWR/JaEhhlaio3hhp5KaVlJtFiOyIkDTKNG5yaH7FjNZlpSh1HRSIeG6dxTCJq0854xhPXxCL+oZAiZEY2JcSs7KG18WgljKBCwWnB1kqIX1qhRYslVt/+cc+Fq6u7uuce3XvPOXs/r5k7uvf8uOfDw+qrs885z3MUEZiZWfnMyzuAmZll4wJuZlZSLuBmZiXlAm5mVlIu4GZmJeUCbmZWUi7glomkGyQ9VPM5JL29yxlSHVPSSkl7u5HJrJtcwHuUpKckHZB0Zs2y35G0rQPH2pYU23fVLd+SLF/Z7mO2U9HyS1qWHHdH3fKFko5Keqpm2VOSpiVNJf+//1LSYM3690kak3RY0guSHpF0k6T5XfxPsoxcwHvbG4Abu3Ssvweuq36Q9HPApcBzXTr+6Spi/jMlXVDz+beA/9dgu38VEYPAu4F/BnwCQNIHgP8BfB04LyJ+DvhN4Bzg3E4Gt/ZwAe9tG4A/lDRUv6LmLO8NNcu2SfqdjMf6GvCbkvqSzx8E7gGO1nz/GyXdLmlf8rpd0htr1q+VtD9Z9+G6vG+UdJuknyRnml+UNJAxa9b88yStk/QPydnsXZLeXLP+byQ9I+mQpO9JemfNuq9I+oKkbyVnww9L+kdNMv0VcH3N5+uAO2fbOCImgPuACyQJ+BzwxxHxpYh4MdlmT0T8fkQ8maZRLF8u4L1tO7AN+MMuHGsf8H+AX04+Nyo2f0TlrPYi4F3AJbx+tnhFkvN9wPnAe+v2/TPgHyf7vh1YCnyyy/n/A7Aa+CVgCXAQ+ELN+vuoZH8LsIPKPwq1Pgh8Gjgb+DHwmSaZvgpcI6lP0j8BzgIenm1jSecCVwI7geVUzrTvbnIMKzAXcPsk8PuSFnXhWHcC10laDgxFxPfr1v9bKmeEz0bEc1SK2bXJun8D/GVEPBYRLwO3VHdKziY/CnwsIl6MiMPAnwLXdDn/vwP+KCL2RsTPkoy/Uf0tJiLuiIjDNeveJWlBzf6bI+KHEfEqleJ+UZM8e4E9VP4xu57Zz763SJoEHgK+S6VtFibrnqluJGmTpElJRyRde/LXWNG8ofkmNpdFxGOStgLrgN0dPtxm4L8AL1D59b/eEuDpms9PJ8uq68br1lUtAt4EjFdqOQAC+mhC0s3AzcnHr0bE755G/vOAeyQdr1k2AwxLeobKGfUHkrzVbRYCh5L3z9TsdwQYpLk7gRuAfwn8IpUz/HqrI+LvahdIeiF5u5ik3zwirknWPUSKtrP8+QzcAD5F5Qx2ac2yl5M/31Sz7K2nc5CIOEKlG+H3aFwA91EpglVvS5YB7OfEC2tvq3n/PDANvDMihpLXguTCXbNMfxoRg8nrVMU7Tf6fAr9Sk2EoIuYnfc+/BVxF5Wx5AbAs2UcNvqcVdwO/CvzfiHi62cY1ngAmgKtP8/iWIxdwIyJ+DPw1lT7c6rLnqPwF/1DSx/phoNlFtTRuBn4pIp5qsO4bwCckLZK0kEr3zleTdXcBN0j6BUlvovKPTjXrceBLwOclvQVA0lJJq9qQt5X8XwQ+I+m8JMMiSVcl684Cfkbl7P1NVLoxTlvSnXQ50NLF5ajMI/1x4FOSPirpbFWcDwy3I5t1ngu4Vf0xcGbdso8Ca6kUnXcC//t0DxIR+yLioVlW/wmVC6uPAruoXOj7k2S/+4DbgQepXOB7sG7fm5LlP5D0EvB3VC7UtVWT/P8VuBf4W0mHgR8A/zxZdyeVbp8JKhdDf9DGTNsj4h8y7PfXVK4tfIjKbw/PU/mH8i+Av2lXPusc+YEOZmbl5DNwM7OScgE3MyuppgVc0nxJP5T0I0mPS/p0svwWSRPJ3AmPSLqy83HNzKyqaR94MkjizIiYktRPZTDAjcAVwFRE3Nb5mGZmVq/pQJ7kdqOp5GN/8sp05XPhwoWxbNmylvd7+eWXOfPM+hskisHZsnG2bJwtm6JmS5trfHz8+Yg4abR0qpGYyQQ+41TmmPhCRDws6VeAfy/pOiq3fn08Ig422HcNsAZgeHiY225r/YR9amqKwcE0g9K6z9mycbZsnC2bomZLm2t0dLTxIK2ISP0ChoAx4AIqN/v3UelH/wxwR7P9R0ZGIouxsbFM+3WDs2XjbNk4WzZFzZY2F7A9GtTUlu5CiYhJKrPXXRERByJiJl4fBXdJK99lZmanJ81dKIuq80Un8yu/F3hC0uKazd4PPNaRhGZm1lCaPvDFwMakH3wecFdEbJX0V5IuonJB8ykqU2mamVmXpLkL5VFgRYPlni/YzCxHng8c2LJzgg3372Hf5DRLhgZYu2o5q1csbb6jmVmOer6Ab9k5wfrNu5g+NgPAxOQ06zfvAnARN7NC6/m5UDbcv+e14l01fWyGDffvySmRmVk6PV/A901Ot7TczKwoer6ALxkaaGm5mVlR9HwBX7tqOQP9Jz6/daC/j7Wr2v4wFzOztur5i5jVC5W+C8XMyqbnCzhUirgLtpmVTc93oZiZlZULuJlZSbmAm5mVlAu4mVlJuYCbmZWU70LJiSfQMrPT5QKeA0+gZWbt4C6UHHgCLTNrBxfwHHgCLTNrBxfwHHgCLTNrBxfwHHgCLTNrB1/EzIEn0DKzdnABz4kn0DKz0+UuFDOzknIBNzMrKRdwM7OScgE3MyspF3Azs5JyATczKykXcDOzknIBNzMrKRdwM7OSKvxIzC07JzjwzGF+e923Gg4594MRzKxXFfoMvPrgg6Mzxwlef/DBlp0TJ6yfmJxuuN7MbC4rdAFv9uADPxjBzHpZ0wIuab6kH0r6kaTHJX06Wf5mSQ9IejL58+x2h2v24AM/GMHMelmaM/CfAZdHxLuAi4ArJF0KrAO+ExHnA99JPrdVswcf+MEIZtbLmhbwqJhKPvYnrwCuAjYmyzcCq9sdrtmDD/xgBDPrZYqI5htJfcA48HbgCxFxk6TJiBiq2eZgRJzUjSJpDbAGYHh4eGTTpk0tBZycPsarrxxh/xE4o28ewwvmMzTQf8L6A4de4ejM8YbrO21qaorBwcGuHa8VzpaNs2XjbK1Lm2t0dHQ8Ii4+aUVEpH4BQ8AYcAEwWbfuYLP9R0ZGIouxsbFM+3WDs2XjbNk4WzZFzZY2F7A9GtTUlu5CiYhJYBtwBXBA0mKA5M9nW/kuMzM7PWnuQlkkaSh5PwC8F3gCuBe4PtnseuCbHcpoZmYNpBmJuRjYmPSDzwPuioitkr4P3CXpI8BPgA90MKeZmdVpWsAj4lFgRYPlLwDv6UQoMzNrrtAjMc3MbHYu4GZmJeUCbmZWUi7gZmYl5QJuZlZSLuBmZiXlAm5mVlIu4GZmJeUCbmZWUi7gZmYl5QJuZlZSLuBmZiXlAm5mVlIu4GZmJZVmPvCet2XnBBvu38O+yWmWDA2wdtVyVq9YmncsM+txLuBNbNk5wfrNu5g+NgPAxOQ06zfvAnARN7NcuQuliQ3373mteFdNH5thw/17ckpkZlbhAt7EvsnplpabmXWLC3gTS4YGWlpuZtYtLuBNrF21nIH+vhOWDfT3sXbV8pwSmZlV+CJmE9ULlb4LxcyKxgU8hdUrlrpgm1nhuAvFzKykXMDNzErKBdzMrKTcB94FHopvZp3gAt5hHopvZp3iLpQO81B8M+sUF/AO81B8M+sUF/AO81B8M+sUF/AO81B8M+sUX8TsMA/FN7NOcQHvAg/FN7NOaNqFIulcSWOSdkt6XNKNyfJbJE1IeiR5Xdn5uGZmVpXmDPxV4OMRsUPSWcC4pAeSdZ+PiNs6F8/MzGbTtIBHxH5gf/L+sKTdgPsDzMxypohIv7G0DPgecAHwB8ANwEvAdipn6Qcb7LMGWAMwPDw8smnTppZDTk1NMTg42PJ+3eBs2ThbNs6WTVGzpc01Ojo6HhEXn7QiIlK9gEFgHLg6+TwM9FHpR/8McEez7xgZGYksxsbGMu3XDc6WjbNl42zZFDVb2lzA9mhQU1PdhSKpH7gb+FpEbE4K/4Ga9V8Ctqb5LrOsPCmY2YmaFnBJAr4M7I6Iz9UsXxyV/nGA9wOPdSaimScFM2skzUjMy4Brgcvrbhn8c0m7JD0KjAIf62RQ622eFMzsZGnuQnkIUINV325/HLPGPCmY2ck8F4qVgicFMzuZC7iVgicFMzuZ50KxUvCkYGYncwG30vCkYGYncheKmVlJuYCbmZWUC7iZWUm5gJuZlZQLuJlZSbmAm5mVlG8jLDDPvuc2MDsVF/CC8ux7bgOzZtyFUlCefc9tYNaMC3hBefY9t4FZMy7gBeXZ99wGZs24gBeUZ99zG5g144uYBeXZ99wGZs24gBeYZ99zG5idirtQzMxKygXczKykXMDNzErKfeBzRKMh50NdOEYe/dNFyWGWN5+BzwHVIecTk9MErw85n5w+1vFjbNk50bZjlCmHWRG4gM8Bsw05P3DolY4fo9vD2ouSw6wIXMDngNmGlh+dOd7xY3R7WHtRcpgVgfvA54AlQwNMNChgZ/TN/u9zq/3Isx2jOqy9W/3SzXKY9RKfgc8Bsw05H14wv+H2WfqRTzWsvZv90h5eb/Y6F/A5YPWKpXz26gtZOjSAgKVDA3z26gsZGuhvuH2WfuTZjrF6xdKu9kufKodZr3EXyhzRaMj5tm1PNtw2az/ybMPau90v7eH1ZhU+A+9B7Z6m1dO+muXDBbwHtbsf2f3SZvlwF0oPavc0rZ721SwfLuA9qt39yO6XNuu+pl0oks6VNCZpt6THJd2YLH+zpAckPZn8eXbn45qZWZUi4tQbSIuBxRGxQ9JZwDiwGrgBeDEibpW0Djg7Im461XddfNZZsX1kpOWQk5OTDA0NtbxfNzhbNs6WjbNlU9RsaXPpu98dj4iL65c3PQOPiP0RsSN5fxjYDSwFrgI2JpttpFLUzcysS1rqA5e0DFgBPAwMR8R+qBR5SW+ZZZ81wBqA4eFhtt1yS8shp6amGBwcbHm/buiVbJPTxzhw6BWOzhznjL55DC+YP+tAoW5nazdny8bZWpc61+ho4+URkeoFDFLpPrk6+TxZt/5gs+8YGRmJLMbGxjLt1w29kO2eHXvjHZ+4L867aetrr3d84r64Z8fe3LN1grNl42ytS5sL2B4Namqq+8Al9QN3A1+LiM3J4gNJ/3i1n/zZNN9l5eMpXM2KKc1dKAK+DOyOiM/VrLoXuD55fz3wzfbHsyLwFK5mxZSmD/wy4Fpgl6RHkmU3A7cCd0n6CPAT4AMdSWi5m4tTuOb9WLa8j29zQ9MCHhEPAZpl9XvaG8eKaO2q5azfvOuEbpQyD5WvTn9b/e+pTn8LdKWI5n18mzs8F4o1NdemcM27Tz/v49vc4aH0lspcGiqfd59+3se3ucNn4NZz8p7+Nu/j29zhAm49Z/Qdi1pa3m6eftfaxV0o1nPGnniupeXt5ul3rV1cwK3nFKEPei5dU7D8uAvFeo77oG2ucAG3ntOoDxrgyNFX2bJzIodEZtm4gFvPqd7XXj+b4sEjx1i/eReT08dySmbWGhdw60mrVyzlzDeefAlo+tgMBw69kkMis9a5gFtP2rJzouH8LgBHZ453OY1ZNi7g1nOqc5HM5ow+/7WwcvBthNZzGs1FUjXQ38fwgjO6nMgsG59qWM851f3ejS5umhWVC7j1nNnu9146NNCWwTVbdk5w2a0P8vPrvsVltz7oWxOtY1zAred0ci6Sav/6xOQ0wetzfbuIWye4gFvP6eT85p7r27rJFzGtJ3VqLpIizLNivcNn4GZt5HlWrJtcwM3ayHN9Wze5C8WsjTzXt3WTC7hZm3Vrru8tOyf8D0WPcwE3K6Hq7YrVO16qtysCLuI9xH3gZiXk2xUNXMDNSsm3Kxq4gJuVkm9XNHABtxLw3CIn8+2KBr6IaQXni3WN+XZFAxdwK7hTXazr9WLVrdsVrbjchWKF1u2LdVt2TrDnmcPurrFScAG3Quvmxbpqd83RmeOeCtZKwQXcCq2bF+t8b7WVjfvArdA6dbGu0TD0TnXXeMi7dUrTAi7pDuDXgGcj4oJk2S3AR4Hnks1ujohvdyqk9bZ2X6yb7c6WBQP9TE4fO2n7eRI/v+5bmYqv76KxTkrThfIV4IoGyz8fERclLxdvK43ZukokTuquAZiJyNwn7m4Z66SmBTwivge82IUsZl0xW5fI5JFjfPbqCzmjbx4C+qSTtmm1+HrIu3WSIqL5RtIyYGtdF8oNwEvAduDjEXFwln3XAGsAhoeHRzZt2tRyyKmpKQYHB1verxucLZs8s+155jBHZ46ftPyMvnksf+tZr2XbNXFo1u+4cOmCthyrVf5/mk2ns01OH+PAoVc4OnOcM/rmMbxgPkMD/W3LNTo6Oh4RF9cvz1rAh4HngQD+M7A4Ij7c7Hsuvvji2L59e9Pj1du2bRsrV65seb9ucLZs8sxW3y8Nla6T6oONq9kuu/VBJhqcKS8dGuB/rbu8Lcdqlf+fZtPJbKfz/zhtLkkNC3im2wgj4kBEzETEceBLwCVZvscsD2mfSt+OWxjTHsvKK8/rHJluI5S0OCL2Jx/fDzzWvkhmnZfmzpbVK5ay/ekX+cbDP2Umgj6Jfz3S+h0xHvI+t+V5naPpGbikbwDfB5ZL2ivpI8CfS9ol6VFgFPhYh3Oadd2WnRPcPT7BTNLNOBPB3eMTHplpJ8hzat80d6F8MCIWR0R/RJwTEV+OiGsj4sKI+KcR8es1Z+Nmc4ZvAbQ08pza1yMxzWbhWwAtjTyn9nUBN5vFkqGBhneh+Kk3Vi+v6xyezMpsFn7qjRWdz8DNZuGn3ljRuYCbnYJvAbQicxeKmVlJ+QzcrMs8P7i1iwu4WRd5fnBrJ3ehmHWRBwdZO7mAm3WRBwdZO7mAm3VRnvNm2NzjAm7WRR4cZO3ki5hmXeTBQdZOLuBmXebBQdYu7kIxMyspF3Azs5JyATczKykXcDOzknIBNzMrKRdwM7OScgE3MyspF3Azs5JyATczKykXcDOzknIBNzMrKRdwM7OScgE3MyspF3Azs5JyATczKykXcDOzkvIDHczMUtiycyLTk5Sy7peGC7iZWRNbdk6wfvMupo/NADAxOc36zbsATlmMs+6XlrtQzMya2HD/nteKcNX0sRk23L+nI/ul1bSAS7pD0rOSHqtZ9mZJD0h6Mvnz7LakMTMroH2T0y0tP9390kpzBv4V4Iq6ZeuA70TE+cB3ks9mZnPSkqGBlpaf7n5pNS3gEfE94MW6xVcBG5P3G4HVbUljZlZAa1ctZ6C/74RlA/19rF21vCP7paWIaL6RtAzYGhEXJJ8nI2KoZv3BiGjYjSJpDbAGYHh4eGTTpk0th5yammJwcLDl/brB2bJxtmycLZt2ZJucPsaBQ69wdOY4Z/TNY3jBfIYG+k9rv7S5RkdHxyPi4pNWRETTF7AMeKzm82Td+oNpvmdkZCSyGBsby7RfNzhbNs6WjbNlU9RsaXMB26NBTc16F8oBSYsBkj+fzfg9ZmaWUdYCfi9wffL+euCb7YljZmZppbmN8BvA94HlkvZK+ghwK/A+SU8C70s+m5lZFzUdiRkRH5xl1XvanMXMzFrgkZhmZiWV6jbCth1Meg54OsOuC4Hn2xynXZwtG2fLxtmyKWq2tLnOi4hF9Qu7WsCzkrQ9Gt0DWQDOlo2zZeNs2RQ12+nmcheKmVlJuYCbmZVUWQr4X+Qd4BScLRtny8bZsilqttPKVYo+cDMzO1lZzsDNzKyOC7iZWUkVpoA3evJP3fqVkg5JeiR5fbKL2c6VNCZpt6THJd3YYBtJ+m+SfizpUUnvLlC2XNpO0nxJP5T0oyTbpxtsk1e7pcmW589cn6SdkrY2WJdLm6XMlmebPSVpV3Lc7Q3W59ZuKbJla7dGUxTm8QJ+EXg3NdPW1q1fSWVO8jyyLQbenbw/C/h74BfqtrkSuA8QcCnwcIGy5dJ2SVsMJu/7gYeBSwvSbmmy5fkz9wfA1xsdP682S5ktzzZ7Clh4ivW5tVuKbJnarTBn4NH4yT+FEBH7I2JH8v4wsBuof6T0VcCdUfEDYKg65W4BsuUiaYup5GN/8qq/ap5Xu6XJlgtJ5wC/Cvz3WTbJpc1SZiuy3NqtUwpTwFP6F8mvvPdJemceAVR5OtEKKmdstZYCP635vJcuF9JTZIOc2i75dfsRKnPGPxARhWm3FNkgn3a7HfhPwPFZ1uf5s3Y7p84G+f09DeBvJY2r8iSwenm2W7NskKHdms5GWCA7qMwHMCXpSmALcH43A0gaBO4G/mNEvFS/usEuXTuja5Itt7aLiBngIklDwD2SLoiI2uscubVbimxdbzdJvwY8GxHjklbOtlmDZR1vs5TZ8vx7ellE7JP0FuABSU8kv9lX5fl3tFm2TO1WmjPwiHip+itvRHwb6Je0sFvHl9RPpUB+LSI2N9hkL3BuzedzgH1FyJZ32yXHnQS2AVfUrcqt3apmy5ZTu10G/Lqkp4BNwOWSvlq3TV5t1jRbnj9rEbEv+fNZ4B7gkrpNcvtZa5Yta7uVpoBLeqskJe8voZL9hS4dW8CXgd0R8blZNrsXuC650n0pcCgi9hchW15tJ2lRcnaLpAHgvcATdZvl1W5Ns+XRbhGxPiLOiYhlwDXAgxHxobrNcmmzNNly/Fk7U9JZ1ffALwP1d7Tl9bPWNFvWditMF4oqT/5ZCSyUtBf4FJULS0TEF4HfAH5P0qvANHBNJJdvu+Ay4FpgV9JnCnAz8LaafN+mcpX7x8AR4LcLlC2vtlsMbJTUR+UH8q6I2Crpd2uy5dVuabLl+TN3goK0WUMFabNhKt1gUKlrX4+I/1mQdkuTLVO7eSi9mVlJlaYLxczMTuQCbmZWUi7gZmYl5QJuZlZSLuBmZiXlAm5mVlIu4GZmJfX/AcSy17XRTA0AAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(mtcars.wt,mtcars.mpg)\n",
    "plt.axhline(np.mean(mtcars.mpg), color=\"red\")\n",
    "plt.grid()\n",
    "plt.title(\"Null Model - Mean MPG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll implement the model using scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean RMSE is 6.183757\n",
      "Mean RMSE for cross_val_score is 6.088744 \n"
     ]
    }
   ],
   "source": [
    "# Let's import what we need - could be redundant but\n",
    "# this will show you what you need to reproduce this\n",
    "\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from numpy import mean\n",
    "from numpy import absolute\n",
    "from numpy import sqrt\n",
    "\n",
    "# Reread the mtcars file\n",
    "url = \"https://raw.githubusercontent.com/steviep42/bios534_spring_2020/master/data/mtcars.csv\"\n",
    "mtcars = pd.read_csv(url)\n",
    "\n",
    "# Create the X, y combo\n",
    "X = mtcars.drop(\"mpg\",axis=1)\n",
    "y = mtcars.mpg\n",
    "\n",
    "# Now we make a Dummy model that uses the mean of the dependent variable\n",
    "dummy_mean = DummyRegressor(strategy='mean')\n",
    "\n",
    "# Set up a scores list to collect RMSE as we do KFold validation\n",
    "scores = []\n",
    "\n",
    "# try with KFold\n",
    "kf = KFold(n_splits=4,shuffle=True)\n",
    "for train_index, test_index in kf.split(X):\n",
    "     X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "     y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "     dummy_mean.fit(X_train,y_train)\n",
    "     ypreds = dummy_mean.predict(X_test)\n",
    "     scores.append(mean_squared_error(y_test,ypreds,squared=False))\n",
    "\n",
    "print(\"Mean RMSE is %f\" % mean(scores))\n",
    "\n",
    "# The RMSE emerging from the following  should be comparable to what we did above \n",
    "# After all, this is just an automatic way of doing the above that uses the same\n",
    "# folds created by the KFold object\n",
    "\n",
    "cross_val_scores = cross_val_score(dummy_mean, \n",
    "                                   X, \n",
    "                                   y, \n",
    "                                   scoring='neg_mean_squared_error',\n",
    "                                   cv=kf, \n",
    "                                   n_jobs=-1)\n",
    "\n",
    "print(\"Mean RMSE for cross_val_score is %f \" % sqrt(mean(absolute(cross_val_scores))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the RMSE is not particularly different. After all, we used the same folds and the second approach just implemented **cross_val_score** function to make things easier albeit less transparent. The larger point here is that I wanted to show how to implement a null / baseline model using scikit. We've already looked at a number of examples involving regression and variants thereof but here is one more just to contrast this with the dummy model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean RMSE for cross_val_score is 5.076318 \n"
     ]
    }
   ],
   "source": [
    "# Look at an actual Regresssion Model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression()\n",
    "cross_val_scores = cross_val_score(reg, \n",
    "                                   X, \n",
    "                                   y, \n",
    "                                   scoring='neg_mean_squared_error',\n",
    "                                   cv=kf, \n",
    "                                   n_jobs=-1)\n",
    "print(\"Mean RMSE for cross_val_score is %f \" % sqrt(mean(absolute(cross_val_scores))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to know that we don't have to create a separate KFold object to do cross fold validation. We can just tell **cross_validate** or **cross_val_score** to use its own validation just by supplying the desired number of folds. Here we specify 3 folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean RMSE for cross_val_score is 4.540624 \n"
     ]
    }
   ],
   "source": [
    "cross_val_scores = cross_val_score(reg, \n",
    "                                   X, \n",
    "                                   y, \n",
    "                                   scoring='neg_mean_squared_error',\n",
    "                                   cv=3, \n",
    "                                   n_jobs=-1)\n",
    "print(\"Mean RMSE for cross_val_score is %f \" % sqrt(mean(absolute(cross_val_scores))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the general idea is to be able to easily \"drop in\" new methods (also known as \"estimators\") without having to change the workflow too much. For exampe, we could easily implement regression using Support Vector Regression along with the existing cross validation approach. Of course, we have to load the appropriate function to implement the SVR() estimator but we don't need to change much else. Of course, this isn't always going to be so easy because some methods might, for example, require scaling of the data or some other type of transformation although from a workflow point of view, you should not have to change your thinking very much. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean RMSE for cross_val_score using SVR is 4.473371 \n"
     ]
    }
   ],
   "source": [
    "# Let's do Support Vector Regression\n",
    "from sklearn.svm import SVR\n",
    "svr_mod = SVR()\n",
    "cross_val_scores = cross_val_score(svr_mod, \n",
    "                                   X, \n",
    "                                   y, \n",
    "                                   scoring='neg_mean_squared_error',\n",
    "                                   cv=3, \n",
    "                                   n_jobs=-1)\n",
    "print(\"Mean RMSE for cross_val_score using SVR is %f \" % sqrt(mean(absolute(cross_val_scores))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative Input Formats\n",
    "\n",
    "One of the more challening things when working with data is that some methods seem to want the input in a certain format. Let's revisit the opening section when we separated the mtcars data into X and y which is the preferred way of indicating what is being used to predict and outcome. In using various scikit functions, I find myself having to reshape the data or turning it into an array to accomodate the input requirements of various functions. In all fairness, I have had to do the same thing when using R so it's not unique to a given language. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X is of type: <class 'pandas.core.frame.DataFrame'>\n",
      "y is of type: <class 'pandas.core.series.Series'>\n",
      "RMSE:  3.1206970547252944\n"
     ]
    }
   ],
   "source": [
    "y = mtcars.mpg\n",
    "X = mtcars.drop('mpg',axis=1)\n",
    "\n",
    "# X is a pandas dataframe\n",
    "print(\"X is of type:\",type(X))\n",
    "\n",
    "# y is a Series which is comparable to a vector in R\n",
    "print(\"y is of type:\",type(y))\n",
    "\n",
    "# Next we create a training and test pair with 80 / 20 proportions\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2)\n",
    "\n",
    "# Create and fit the model\n",
    "lr_mod = LinearRegression()\n",
    "lr_mod.fit(X_train,y_train)\n",
    "\n",
    "# Do some scoring\n",
    "y_lr_preds = lr_mod.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(\"RMSE: \",np.sqrt(mean_squared_error(y_test,y_lr_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So compare this to the version we used ealrier when we first converted the mtcars data frame into a numpy array. At this point things still work although we have lost the feature names in the X input which is now an array. You might feel that this is academic but later when we look at classification predictions, you will see that knowing how to reshape and manipulate X and y will come in handy as you use various functions in scikit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X is of type: <class 'numpy.ndarray'>\n",
      "y is of type: <class 'numpy.ndarray'>\n",
      "RMSE:  3.336254388640006\n"
     ]
    }
   ],
   "source": [
    "mtvals = mtcars.values            # creates a numpy array\n",
    "\n",
    "# note we have to index by number since the names are no longer available\n",
    "y = mtvals[:,0]         # Gets the mpg column\n",
    "X = mtvals[:,1:10]      # Gets everything BUT the mpg column\n",
    "\n",
    "# X is a numpy array\n",
    "print(\"X is of type:\",type(X))\n",
    "\n",
    "# y is a numpy array\n",
    "print(\"y is of type:\",type(y))\n",
    "\n",
    "# Next we create a training and test pair with 80 / 20 proportions\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2)\n",
    "\n",
    "# Create and fit the model\n",
    "lr_mod = LinearRegression()\n",
    "lr_mod.fit(X_train,y_train)\n",
    "\n",
    "# Do some scoring\n",
    "y_lr_preds = lr_mod.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(\"RMSE: \",np.sqrt(mean_squared_error(y_test,y_lr_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing we could do is to apply transformation techniques (aka \"transformers\") to pre-process the data. In particular, scaling data is a common activity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  3.0337571648802766\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Let's scale the X training data - we need to fit AND transform it\n",
    "X_train_transformed = scaler.fit_transform(X_train)\n",
    "model = LinearRegression().fit(X_train_transformed, y_train)\n",
    "\n",
    "# Note that we can now make a prediction but need to just transform\n",
    "# the data on X_test\n",
    "\n",
    "X_test_transformed = scaler.transform(X_test)\n",
    "mean_squared_error(y_test, model.predict(X_test_transformed))\n",
    "print(\"RMSE: \",np.sqrt(mean_squared_error(y_test, model.predict(X_test_transformed))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will explore this in greater detail later but the larger point is that we can use a number of transformers as part of a pipeline to process datsa prior to using it in a model. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preventing Data Leakage\n",
    "\n",
    "Data Leakage occurs when we have information from a test set somehow influencing the model that is built on the training set. In our above approach, we are splitting the data set into folds using methods from scikit-learn which is fine however each test fold is also being use K-1 times as part of the training set which means that we are in effect training our model using data that we've seen before. Once way to address this is to adopt the following approach:\n",
    "\n",
    "<img src=\"pics/kf33.png\" width =\"600\" height=600>\n",
    "\n",
    "The advantage here is that we carve out a test data frame that is not used in anyway to train the model or participates in the cross validation process. After we have generated a good estimate of RMSE using our training data and K-fold validation we can THEN apply any resulting model the holdout test data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean RMSE for cross_val_score is 4.560465 \n"
     ]
    }
   ],
   "source": [
    "mtvals = mtcars.values  # Create an array version of the data\n",
    "y = mtvals[:,0]         # Gets the mpg column\n",
    "X = mtvals[:,1:10]      # Gets everything BUT the mpg column\n",
    "\n",
    "# Now create training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.20)\n",
    "\n",
    "# Now do some K-fold validation - well try this for both X and X_train\n",
    "reg = LinearRegression()\n",
    "cross_val_scores = cross_val_score(reg, \n",
    "                                   X_train, \n",
    "                                   y_train, \n",
    "                                   scoring='neg_mean_squared_error',\n",
    "                                   cv=kf, \n",
    "                                   n_jobs=-1)\n",
    "print(\"Mean RMSE for cross_val_score is %f \" % sqrt(mean(absolute(cross_val_scores))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.68"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds = reg.fit(X_train,y_train).predict(X_test)\n",
    "round(mean_squared_error(y_test,test_preds)**0.5,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sets\n",
    "\n",
    "Scikit comes with a number of data sets which can be used to test and practice various machine learning activities. You will see these referred to in the scikit documentation as well as examples on the Internet. These datasets reside in the sklearn.datasets module.\n",
    "\n",
    "load_boston(*[, return_X_y]) - boston house-prices dataset (regression).\n",
    "\n",
    "load_iris(*[, return_X_y, as_frame]) - iris dataset (classification).\n",
    "\n",
    "load_diabetes(*[, return_X_y, as_frame])- diabetes dataset (regression).\n",
    "\n",
    "load_digits(*[, n_class, return_X_y, as_frame]) - the digits dataset (classification).\n",
    "\n",
    "load_linnerud(*[, return_X_y, as_frame]) - physical excercise linnerud dataset.\n",
    "\n",
    "load_wine(*[, return_X_y, as_frame]) - wine dataset (classification).\n",
    "\n",
    "load_breast_cancer(*[, return_X_y, as_frame]) - breast cancer wisconsin dataset (classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.78,   2.14,  11.2 , 100.  ],\n",
       "       [  2.36,   2.67,  18.6 , 101.  ],\n",
       "       [  1.95,   2.5 ,  16.8 , 113.  ],\n",
       "       [  2.59,   2.87,  21.  , 118.  ]])"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "X, y = load_wine(return_X_y=True)\n",
    "\n",
    "# First 5 rows and 5 columns of the wine predictors\n",
    "X[1:5,1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It might be better to download the entire object and then select attributes as desired:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_stuff = load_wine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit also provides access to a number of \"real world\" data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = boston.data\n",
    "y = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean RMSE for cross_val_score is 5.040581 \n"
     ]
    }
   ],
   "source": [
    "# Now create training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.20)\n",
    "\n",
    "# Now do some K-fold validation - well try this for both X and X_train\n",
    "reg = LinearRegression()\n",
    "cross_val_scores = cross_val_score(reg, \n",
    "                                   X_train, \n",
    "                                   y_train, \n",
    "                                   scoring='neg_mean_squared_error',\n",
    "                                   cv=kf, \n",
    "                                   n_jobs=-1)\n",
    "print(\"Mean RMSE for cross_val_score is %f \" % sqrt(mean(absolute(cross_val_scores))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start out with, let's consider the cross fold validation scenario. In previous examples we have explicitly created folds by using the KFolds function which allows us to explicitly chop up the data into a number of folds. On the other hand we don't have to do so directly. We can create a cross_validate object and tell it how many folds to use and it will handle the separation of the data for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts of the diabetes columns:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "diabetes\n",
       "neg    500\n",
       "pos    268\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/steviep42/bios534_spring_2020/master/data/pima.csv\"\n",
    "pm = pd.read_csv(url, sep=',')\n",
    "\n",
    "\n",
    "# How many people have diabetes ? \n",
    "print(\"Value counts of the diabetes columns:\\n\")\n",
    "pm.groupby('diabetes').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "X = pm.drop('diabetes',axis=1)\n",
    "y = pm.diabetes\n",
    "\n",
    "# Next we create a training and test pair with 80 / 20 proportions\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=2)\n",
    "#                                                    stratify=y)\n",
    "\n",
    "rf = RandomForestClassifier(200)\n",
    "rezults = cross_validate(rf,X_train,y_train,cv=8)\n",
    "rezults['test_score'].mean().round(3)\n",
    "\n",
    "rf.fit(X_train,y_train).score(X_train,y_train)\n",
    "rf.fit(X_train,y_train).score(X_test,y_test).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, since we do have something of a class imbalance we need to insure that the folds reflect class proportions of positive to negative across the folds. In reality, the cross_validate function does that for us where possible but let's see how we might do that ourselves when we create the train / test pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training group counts: \n",
      " neg    400\n",
      "pos    214\n",
      "Name: diabetes, dtype: int64\n",
      "testing group counts: \n",
      " neg    100\n",
      "pos     54\n",
      "Name: diabetes, dtype: int64\n",
      "training group diabetes percentages 34.85\n",
      "testing group diabetes percentages 35.06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.77      0.87      0.82       100\n",
      "         pos       0.68      0.52      0.59        54\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.73      0.69      0.70       154\n",
      "weighted avg       0.74      0.75      0.74       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Next we create a training and test pair with 80 / 20 proportions\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=2,\n",
    "                                                    stratify=y)\n",
    "\n",
    "train_counts = y_train.value_counts()\n",
    "test_counts = y_test.value_counts()\n",
    "print(\"training group counts: \\n\",train_counts)\n",
    "print(\"testing group counts: \\n\",test_counts)\n",
    "\n",
    "# \n",
    "\n",
    "print(\"training group diabetes percentages\",round(train_counts[1]/train_counts.sum()*100,2))\n",
    "print(\"testing group diabetes percentages\",round(test_counts[1]/test_counts.sum()*100,2))\n",
    "\n",
    "rezults = cross_validate(rf,X_train,y_train,cv=8)\n",
    "rezults['test_score'].mean().round(2)\n",
    "\n",
    "y_test_preds = rf.fit(X_train,y_train).predict(X_test)\n",
    "\n",
    "class_report = metrics.classification_report(y_test, \n",
    "                                             y_test_preds)\n",
    "\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training group counts: \n",
      " neg    400\n",
      "pos    214\n",
      "Name: diabetes, dtype: int64\n",
      "testing group counts: \n",
      " neg    100\n",
      "pos     54\n",
      "Name: diabetes, dtype: int64\n",
      "training group diabetes percentages 34.85\n",
      "testing group diabetes percentages 35.06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.77      0.88      0.82       100\n",
      "         pos       0.69      0.50      0.58        54\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.73      0.69      0.70       154\n",
      "weighted avg       0.74      0.75      0.74       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Next we create a training and test pair with 80 / 20 proportions\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=2,\n",
    "                                                    stratify=y)\n",
    "\n",
    "train_counts = y_train.value_counts()\n",
    "test_counts = y_test.value_counts()\n",
    "print(\"training group counts: \\n\",train_counts)\n",
    "print(\"testing group counts: \\n\",test_counts)\n",
    "\n",
    "# \n",
    "\n",
    "print(\"training group diabetes percentages\",round(train_counts[1]/train_counts.sum()*100,2))\n",
    "print(\"testing group diabetes percentages\",round(test_counts[1]/test_counts.sum()*100,2))\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=8, random_state=None, shuffle=False)\n",
    "\n",
    "rezults = cross_validate(rf,X_train,y_train,cv=kf)\n",
    "rezults['test_score'].mean().round(2)\n",
    "\n",
    "y_test_preds = rf.fit(X_train,y_train).predict(X_test)\n",
    "\n",
    "class_report = metrics.classification_report(y_test, \n",
    "                                             y_test_preds)\n",
    "\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "static-course",
   "metadata": {},
   "source": [
    "In Data Science much of the data arrives in the form of what one might call tabular or Excel-like structure which is convenenient for importing into a data frame. This then makes it realtively straightforward to use as input with traditional modeling approaches such as regression, support vector machines, decision trees, and naive bayes. \n",
    "\n",
    "<img src=\"pics/ml_graph.png\" width =\"600\" height=600>\n",
    "\n",
    "\n",
    "Moreover, if the data size is manageable on your local computer then maybe sticking with these approaches is fine. On the other hand, we can in fact use Deep Learning tools in the modeling of simple data structures, it's just that it might be over kill. Nonetheless, there are plenty of organizations who more or less do everything with DL approaches under the premise that it centralizes thinking and activity around a basic set of tools. The discussion then becomes about:\n",
    "\n",
    "- model architectures\n",
    "- batch sizes\n",
    "- activation functions\n",
    "- cost functions\n",
    "- learning rates\n",
    "- regularization\n",
    "\n",
    "So while a committment is made to Deep Learning it doesn't then mean that the considerations are few and simple. Deep Learning is ususally discussed in contexts where the data is unstructured to the extent that it is not so easy to \"mold\" it into the tpyical tabular approach. Or if you can, then you have to create a containing super-structure to manage it in total. We could use tools like Python's **numpy** module because it does in fact allow us to flexibly represent data in interesting ways that facilitate computational efficiency. However, it does not run on GPUs which are the next generation processors for aggressive and at-scale computing. \n",
    "\n",
    "\n",
    "<img src=\"pics/numpy.png\" width =\"400\" height=400>\n",
    "\n",
    "\n",
    "This need has led, in part, to the development of things like tensors which allow us to represent unstructured data as arrays of matrices, or arrays of arrays, with all the underlying connectivity (via graphs) being maintained for you so yo don't have to worry about that. Then you can present this structure to Deep Learning networks such as TensorFlow, Keras (which sits on top of Tensorflow), and of course PyTorch. Note that using arrays of arrays/matrices is not a new thing altough calculations of this sort used to require very large \"mainframes\" though now we can run them on laptops. Moever, using tensors gives us efficiencies that allow is to run on both CPUs and GPU without having to change our code. Lastly, tensors, at least as implemented by PyTorch and Tensorflow, can have linkages in the for of Directed Graphs which means they can keep track out calculations over time. \n",
    "\n",
    "<img src=\"pics/tensors.png\" width =\"600\" height=600>\n",
    "\n",
    "<small>https://www.freecodecamp.org/news/get-to-know-tensorflow-js-in-7-minutes-afcd0dfd3d2f/</small>\n",
    "\n",
    "One thing to know is that many times people will use the words **arrays** and **matrices** synonymously. In my view this should not be the case but people smarter than me do it all the time so maybe they know something I don't.\n",
    "\n",
    "<img src=\"pics/moretens.png\" width =\"600\" height=600>\n",
    "\n",
    "However, it is fair to say that Deep Learning is more commonly used in non-traditional contexts such as image classification and object recognition, Natural Language Processing, population segmentation, as well dialogue generation and processing tools (e.g. Siri, Alexa). Also, Deep Learning shines becasue the tensor concept allows us to use at-scale and very large datasets\n",
    "\n",
    "\n",
    "Libraries such as <a href=\"https://keras.io/\">Keras</a> can \"sit on top\" of Tensorflow to leverage one's knowledge of Python which can make the Deep Learning experuience easier if you alreadu know Python. <a href=\"http://pytorch.org\">PyTorch</a> is also a framework which allows use of Python as an interface language though it does not rely upon Tensorflow. Here are some benefits of PyTorch which you might recall from last week's lecture. \n",
    "\n",
    "- Optimize performance in both research and production by taking advantage of native support for asynchronous execution of collective operations and peer-to-peer communication that is accessible from Python and C++.\n",
    "    \n",
    "- PyTorch supports an end-to-end workflow from Python to deployment on iOS and Android. \n",
    "\n",
    "- PyTorch is well supported on major cloud platforms, providing frictionless development and easy scaling through prebuilt images, large scale training on GPUs, ability to run models in a production scale environment, and more.\n",
    "    \n",
    "<h3>Autograd module</h3>\n",
    "\n",
    "<p>PyTorch uses a method called <b>automatic differentiation</b>. A recorder records what operations have performed, and then it replays it backward to compute the gradients. This method is especially powerful when building neural networks to save time on one epoch (trip through the network) by calculating differentiation of the parameters at the forward pass.</p>\n",
    "    \n",
    "<h3>Optim module</h3>\n",
    "\n",
    "<b>torch.optim</b> is a module that implements various optimization algorithms used for building neural networks. Most of the commonly used methods are already supported, so there is no need to build them from scratch.\n",
    "\n",
    "<h3>nn module</h3>\n",
    "\n",
    "<p>PyTorch autograd makes it easy to define computational graphs and take gradients, but raw autograd can be a bit too low-level for defining complex neural networks. This is where the nn module can help. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "computational-happiness",
   "metadata": {},
   "source": [
    "Let's continue with PyTorch and dig some more into it. In Python we tend to use numpy for manipulating matrices as it is optimized for managing large collections of numbers in a memory efficient manner while also supporting most of the common linear algebra techniques likely to be of interest to a Data Scientist. \n",
    "\n",
    "We can take numpy arrays and use them with PyTorch since PyTorch opens the door to using GPUs which can greatly speed up the creation of models using very large data sets. The so called \"Deep Learning\" revolution has involved using things like Google's <a href=\"https://www.tensorflow.org/\">Tensorflow </a>product which requires learning approaches specific to that environment. \n",
    "\n",
    "If you have numpy arrays you can create tensors from them. Again, this is something we learned previously. Using tensors gives us the ability to benefit from GPUs but when looking or viewing tensors they look a lot like arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "velvet-auckland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 73.,  67.,  43.],\n",
      "        [ 91.,  88.,  64.],\n",
      "        [ 87., 134.,  58.],\n",
      "        [102.,  43.,  37.],\n",
      "        [ 69.,  96.,  70.]], dtype=torch.float64)\n",
      "tensor([ 56.,  81., 101., 119., 133.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "inputs = np.array([[73, 67, 43], \n",
    "                   [91, 88, 64], \n",
    "                   [87, 134, 58], \n",
    "                   [102, 43, 37], \n",
    "                   [69, 96, 70]], dtype='float')\n",
    "\n",
    "targets = np.array([56, 81, 101, 119, 133], dtype='float')\n",
    "                    \n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "inputs = torch.from_numpy(inputs)\n",
    "targets = torch.from_numpy(targets)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "serial-shade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n",
      "tensor([[ 73.,  67.,  43.],\n",
      "        [ 91.,  88.,  64.],\n",
      "        [ 87., 134.,  58.]], dtype=torch.float64)\n",
      "Tensor of type: torch.float64\n"
     ]
    }
   ],
   "source": [
    "# Tensors can be indexed as matrices\n",
    "print(inputs.shape)\n",
    "\n",
    "# Get first three rows\n",
    "print(inputs[0:3,:])\n",
    "\n",
    "# Print type of tensor\n",
    "print(\"Tensor of type:\",inputs.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worldwide-alcohol",
   "metadata": {},
   "source": [
    "We can reshape the tensors to suit our purposes. This is usually, of not always, motivated by an interest in some form of linear algebrea computation. That is, multipling one tensor by another has to make operating sense frame a matrix multiplication point of view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "joined-breathing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([41561., 42299., 27163.], dtype=torch.float64)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication NOT element wise multiplication\n",
    "targets @ inputs\n",
    "\n",
    "# but not\n",
    "# inputs @ targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "naval-labor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 56.,  81., 101., 119., 133.], dtype=torch.float64) \n",
      "\n",
      "tensor([[ 56.],\n",
      "        [ 81.],\n",
      "        [101.],\n",
      "        [119.],\n",
      "        [133.]], dtype=torch.float64) \n",
      "\n",
      "tensor([[ 73.,  67.,  43.,  91.,  88.],\n",
      "        [ 64.,  87., 134.,  58., 102.],\n",
      "        [ 43.,  37.,  69.,  96.,  70.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(targets,\"\\n\")\n",
    "\n",
    "# Show targets as a 5 x 1 instead of 1 x 5\n",
    "print(targets.view(5,-1),\"\\n\")\n",
    "\n",
    "# Show inputs as a 3 x 5 instead of a 5 x 3\n",
    "print(inputs.view(3,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-behavior",
   "metadata": {},
   "source": [
    "Let's work with some real data. This is the California real estate data set wherein we use features of a home to predict its ultimate selling price. \n",
    "\n",
    "**Data Set Characteristics:**\n",
    "\n",
    "     Number of Instances: 20640\n",
    "\n",
    "     Number of Attributes: 8 numeric, 7 predictive features and 1 target\n",
    "\n",
    "     Attribute Information:\n",
    "        - MedInc        median income in block\n",
    "        - HouseAge      median house age in block\n",
    "        - AveRooms      average number of rooms\n",
    "        - AveBedrms     average number of bedrooms\n",
    "        - Population    block population\n",
    "        - AveOccup      average house occupancy\n",
    "        - Latitude      house block latitude\n",
    "        - Longitude     house block longitude\n",
    "        \n",
    "The *target variable* is the median house value for California districts.\n",
    "\n",
    "This dataset was derived from the 1990 U.S. census, using one row per census\n",
    "block group. A block group is the smallest geographical unit for which the U.S.\n",
    "Census Bureau publishes sample data (a block group typically has a population\n",
    "of 600 to 3,000 people).\n",
    "\n",
    "This dataset was obtained from the StatLib repository.\n",
    "http://lib.stat.cmu.edu/datasets/\n",
    "\n",
    "\n",
    "It can be downloaded/loaded using the\n",
    ":func:`sklearn.datasets.fetch_california_housing` function.\n",
    "\n",
    ".. topic:: References\n",
    "\n",
    "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
    "      Statistics and Probability Letters, 33 (1997) 291-297\n",
    "\n",
    "\n",
    "If we want to employ a method such as regression we could do so. We could also represent the regression problem as a graph. See this [excellent blog post](https://joshuagoings.com/2020/05/05/neural-network/) for more informaton on Deep Learning as applied to Linear Regression.\n",
    "\n",
    "\n",
    "<img src=\"pics/regr_graph.png\" width =\"600\" height=600>\n",
    "\n",
    "\n",
    "<img src=\"pics/regress2.png\" width =\"600\" height=600>\n",
    "\n",
    "We can solve this a number of ways including use of SGD Stochastic Gradient Descent which we have discussed. Thus, we can train the model using the following steps:\n",
    "\n",
    "    Generate predictions\n",
    "\n",
    "    Calculate the loss\n",
    "\n",
    "    Compute gradients w.r.t the weights and biases\n",
    "\n",
    "    Adjust the weights by subtracting a small quantity proportional to the gradient\n",
    "\n",
    "    Reset the gradients to zero\n",
    "\n",
    "We reduce the loss and improve our model using the gradient descent optimization algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "congressional-blake",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20635</th>\n",
       "      <td>1.5603</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.045455</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>845.0</td>\n",
       "      <td>2.560606</td>\n",
       "      <td>0.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20636</th>\n",
       "      <td>2.5568</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.114035</td>\n",
       "      <td>1.315789</td>\n",
       "      <td>356.0</td>\n",
       "      <td>3.122807</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20637</th>\n",
       "      <td>1.7000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.205543</td>\n",
       "      <td>1.120092</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>2.325635</td>\n",
       "      <td>0.923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20638</th>\n",
       "      <td>1.8672</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.329513</td>\n",
       "      <td>1.171920</td>\n",
       "      <td>741.0</td>\n",
       "      <td>2.123209</td>\n",
       "      <td>0.847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20639</th>\n",
       "      <td>2.3886</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.254717</td>\n",
       "      <td>1.162264</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>2.616981</td>\n",
       "      <td>0.894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20640 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Price\n",
       "0      8.3252      41.0  6.984127   1.023810       322.0  2.555556  4.526\n",
       "1      8.3014      21.0  6.238137   0.971880      2401.0  2.109842  3.585\n",
       "2      7.2574      52.0  8.288136   1.073446       496.0  2.802260  3.521\n",
       "3      5.6431      52.0  5.817352   1.073059       558.0  2.547945  3.413\n",
       "4      3.8462      52.0  6.281853   1.081081       565.0  2.181467  3.422\n",
       "...       ...       ...       ...        ...         ...       ...    ...\n",
       "20635  1.5603      25.0  5.045455   1.133333       845.0  2.560606  0.781\n",
       "20636  2.5568      18.0  6.114035   1.315789       356.0  3.122807  0.771\n",
       "20637  1.7000      17.0  5.205543   1.120092      1007.0  2.325635  0.923\n",
       "20638  1.8672      18.0  5.329513   1.171920       741.0  2.123209  0.847\n",
       "20639  2.3886      16.0  5.254717   1.162264      1387.0  2.616981  0.894\n",
       "\n",
       "[20640 rows x 7 columns]"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/steviep42/bios_534_2021/main/data/cal.csv\"\n",
    "cal = pd.read_csv(url)\n",
    "cal.shape\n",
    "cal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tamil-fifteen",
   "metadata": {},
   "source": [
    "So let's separate data into X (predictor variables) and the target variable being predicted which in this case will be the price of the house that was sold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "different-environment",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numpy = np.array(cal.drop('Price',axis=1), dtype='float32')\n",
    "y_numpy = np.array(cal.Price, dtype='float32')\n",
    "\n",
    "# We normalize the inputs because the features are not on the same scale\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler().fit(X_numpy)\n",
    "X_scaled = scaler.transform(X_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "muslim-access",
   "metadata": {},
   "source": [
    "But we can then turn these into tensors which can be more flexibly used with GPUs, CPUs, and TPUs to benefit from greatly enhanced speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "suffering-compression",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.from_numpy(X_scaled.astype(np.float32))\n",
    "y = torch.from_numpy(y_numpy.astype(np.float32))\n",
    "\n",
    "n_samples, n_features = X_numpy.shape\n",
    "input_size = n_features\n",
    "\n",
    "# Sometimes you will need to reshape the target to match dimensions of predictor\n",
    "y = y.view(y.shape[0],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advised-gibraltar",
   "metadata": {},
   "source": [
    "So we might wish to predict the targets (mpg) in terms of some predictors\n",
    "\n",
    "Price = w11 * MedInc + w12 * HouseAge + w13 * AveRooms ..... + w16 * AveOccup + b1\n",
    "\n",
    "The weights and biases (w11, w12,... w16) can also be represented as matrices, initialized as random values. The first row of w and the first element of b are used to predict the target variable which is <b>Price</b>.The weights and biases (w11, w12,... w163, b1) can also be represented as matrices, initialized as random values. The first row of w and the first element of b are used to predict the target variable which is <b>Price</b>.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "developing-particle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0960, -0.0298, -1.3001, -0.4818,  0.0927,  0.7975]],\n",
      "       requires_grad=True)\n",
      "tensor([0.9297], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Weights and biases - notice how we use the n_features to help us\n",
    "# figure out how many weights we need.\n",
    "\n",
    "w = torch.randn(1, n_features, requires_grad=True)\n",
    "b = torch.randn(1, requires_grad=True)\n",
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaningful-cover",
   "metadata": {},
   "source": [
    "torch.randn creates a tensor with the given shape, with elements picked randomly from a normal distribution with mean 0 and standard deviation 1.\n",
    "\n",
    "Our model is simply a function that performs a matrix multiplication of the inputs and the weights w (transposed) and adds the bias b (replicated for each observation)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demonstrated-palestinian",
   "metadata": {},
   "source": [
    "<img src=\"pics/regress2.png\" width =\"600\" height=600>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identified-webster",
   "metadata": {},
   "source": [
    "The <b>\"@\"</b> represents matrix multiplication in PyTorch, and the <b>.t</b> method returns the transpose of a tensor. The matrix obtained by passing the input data into the model is a set of predictions for the target variables. So what we are doing here is defining a model. We don't really have a neural network. It's just some matrix operations whose loss will be minimized in accordance with some optimization techniques. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "nutritional-hollywood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.5972],\n",
      "        [ 3.2115],\n",
      "        [ 1.2527],\n",
      "        ...,\n",
      "        [-0.2929],\n",
      "        [-0.3539],\n",
      "        [ 0.0915]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def model(x):\n",
    "    return x @ w.t() + b\n",
    "\n",
    "# Generate predictions\n",
    "preds = model(X)\n",
    "\n",
    "# Generate predictions\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graduate-annual",
   "metadata": {},
   "source": [
    "Let's print out the predictions. Are these close ? How would we know ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "applied-burden",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual y values are: \n",
      " tensor([[4.5260],\n",
      "        [3.5850],\n",
      "        [3.5210],\n",
      "        [3.4130],\n",
      "        [3.4220]]) \n",
      "\n",
      "The corresponding predictions are: \n",
      " tensor([[2.5972],\n",
      "        [3.2115],\n",
      "        [1.2527],\n",
      "        [1.6057],\n",
      "        [0.2893]], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(\"Actual y values are: \\n\",y[0:5],\"\\n\")\n",
    "print(\"The corresponding predictions are: \\n\",preds[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulation-potential",
   "metadata": {},
   "source": [
    "You can see a significant difference between our model's predictions and the actual targets because we've initialized our model with random weights and biases. Obviously, we can't expect a randomly initialized model to just work out of the box. This is just a starting point and it's quite common to see a first round of predictions to not be so impressive. \n",
    "\n",
    "Before we try to improve our model, we need a way to evaluate how well our model is performing. We can compare the model's predictions with the actual targets using the following method:\n",
    "\n",
    "    Calculate the difference between the two matrices (preds and targets).\n",
    "    Square all elements of the difference matrix to remove negative values.\n",
    "    Calculate the average of the elements in the resulting matrix.\n",
    "\n",
    "The result is a single number, known as the mean squared error (MSE). Here, we'll implement our own version of this function although PyTorch has a method for doing it also. For now, we'll just stick to our own way of doing this. \n",
    "\n",
    "$$ MSE = \\frac{1}{\\text{n}} \\sum_{\\text{i}=1}^\\text{n} \\left(\\hat{\\text{Y}_\\text{i}} - \\text{Y}_\\text{i}\\right)^2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "turkish-bundle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.39\n"
     ]
    }
   ],
   "source": [
    "# MSE loss \n",
    "def mse(t1, t2):\n",
    "    diff = t1 - t2\n",
    "    return (torch.sum(diff * diff) / diff.numel())\n",
    "\n",
    "# Compute loss\n",
    "loss = mse(preds, y)\n",
    "print(round(loss.item(),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "possible-stock",
   "metadata": {},
   "source": [
    "Here’s how we can interpret the result: On average, each element in the prediction differs from the actual target by the square root of the loss. The result is called the loss because it indicates how bad the model is at predicting the target variables. It represents information loss in the model: the lower the loss, the better the model. See https://www.hackerearth.com/blog/developers/3-types-gradient-descent-algorithms-small-large-data-sets/\n",
    "\n",
    "<img src=\"pics/sgd.png\" width =\"600\" height=600>\n",
    "\n",
    "\n",
    "<h2>Compute Gradients</h2>\n",
    "\n",
    "Since we are using the SGD approach With PyTorch, we can automatically compute the gradient or derivative of the loss with respect to the weights and biases because they have requires_grad set to True. We'll see how this is useful in just a moment.\n",
    "\n",
    "The loss is a function of our weights and biases, and our objective is to find the set of weights where the loss is the lowest. If we plot a graph of the loss with respect to any individual weight or bias element, it will look like the figure shown below. An important insight from calculus is that the gradient indicates the rate of change of the loss, i.e., the loss function's slope w.r.t. the weights and biases.\n",
    "\n",
    "If a gradient element is positive:\n",
    "\n",
    "    increasing the weight element's value slightly will increase the loss\n",
    "    decreasing the weight element's value slightly will decrease the loss\n",
    "    \n",
    "<img src=\"pics/q1.png\" width =\"600\" height=600>\n",
    "\n",
    "\n",
    "If a gradient element is negative:\n",
    "\n",
    "    increasing the weight element's value slightly will decrease the loss\n",
    "    decreasing the weight element's value slightly will increase the loss\n",
    "   \n",
    "<img src=\"pics/q2.png\" width =\"600\" height=600>\n",
    "\n",
    "The increase or decrease in the loss by changing a weight element is proportional to the gradient of the loss w.r.t. that element. This observation forms the basis of the gradient descent optimization algorithm that we'll use to improve our model (by descending along the gradient).\n",
    "\n",
    "We can subtract from each weight element a small quantity proportional to the derivative of the loss w.r.t. that element to reduce the loss slightly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "individual-distance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0960, -0.0298, -1.3001, -0.4818,  0.0927,  0.7975]],\n",
      "       requires_grad=True)\n",
      "tensor([[-0.1484, -0.1246, -3.0630, -3.2132,  0.6335,  1.7217]])\n"
     ]
    }
   ],
   "source": [
    "# Compute gradients\n",
    "loss.backward()\n",
    "\n",
    "# Gradients for weights\n",
    "print(w)\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pursuant-editor",
   "metadata": {},
   "source": [
    "The gradients are stored in the .grad property of the respective tensors. Note that the derivative of the loss w.r.t. the weights matrix is itself a matrix with the same dimensions. We can offset the weights and bias using a \"learning rate\" which allows us to adjust the gradient with this offset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "weekly-handling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.3900, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-2\n",
    "#learning_rate = 1e-5\n",
    "with torch.no_grad():\n",
    "    w -= w.grad * learning_rate\n",
    "    b -= b.grad * learning_rate\n",
    "\n",
    "    # Let's check the loss\n",
    "loss = mse(preds, y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painted-level",
   "metadata": {},
   "source": [
    "So now let's reset the gradients to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "pediatric-status",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0.]])\n",
      "tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "w.grad.zero_()\n",
    "b.grad.zero_()\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "facial-essence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual y values are: \n",
      " tensor([[4.5260],\n",
      "        [3.5850],\n",
      "        [3.5210],\n",
      "        [3.4130],\n",
      "        [3.4220]]) \n",
      "\n",
      "The corresponding predictions are: \n",
      " tensor([[2.6461],\n",
      "        [3.2347],\n",
      "        [1.3199],\n",
      "        [1.6411],\n",
      "        [0.3302]], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions\n",
    "preds = model(X)\n",
    "print(\"Actual y values are: \\n\",y[0:5],\"\\n\")\n",
    "print(\"The corresponding predictions are: \\n\",preds[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "complete-funds",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.1116, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Calculate the loss\n",
    "loss = mse(preds, y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monthly-midnight",
   "metadata": {},
   "source": [
    "So we could do all of this in one go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "threatened-commodity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0974, -0.0285, -1.2694, -0.4496,  0.0863,  0.7803]],\n",
      "       requires_grad=True)\n",
      "tensor([0.9524], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Adjust weights & reset gradients\n",
    "with torch.no_grad():\n",
    "    w -= w.grad * learning_rate\n",
    "    b -= b.grad * learning_rate\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()\n",
    "#\n",
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "ranking-control",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.1116, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Calculate loss\n",
    "preds = model(X)\n",
    "loss = mse(preds, y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "residential-cleanup",
   "metadata": {},
   "source": [
    "So now we can code up a simple loop to make some predictions, compute the loss, compute the gradient, offset the weights and bias, and then reset the gradient to 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "noted-washer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100], Loss: 4.1637\n",
      "Epoch [10/100], Loss: 3.2757\n",
      "Epoch [15/100], Loss: 2.6273\n",
      "Epoch [20/100], Loss: 2.1499\n",
      "Epoch [25/100], Loss: 1.7952\n",
      "Epoch [30/100], Loss: 1.5293\n",
      "Epoch [35/100], Loss: 1.3284\n",
      "Epoch [40/100], Loss: 1.1753\n",
      "Epoch [45/100], Loss: 1.0576\n",
      "Epoch [50/100], Loss: 0.9664\n",
      "Epoch [55/100], Loss: 0.8954\n",
      "Epoch [60/100], Loss: 0.8396\n",
      "Epoch [65/100], Loss: 0.7955\n",
      "Epoch [70/100], Loss: 0.7606\n",
      "Epoch [75/100], Loss: 0.7327\n",
      "Epoch [80/100], Loss: 0.7103\n",
      "Epoch [85/100], Loss: 0.6924\n",
      "Epoch [90/100], Loss: 0.6779\n",
      "Epoch [95/100], Loss: 0.6661\n",
      "Epoch [100/100], Loss: 0.6566\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train for 100 epochs\n",
    "\n",
    "EPOCHS = 100\n",
    "mse_list = []\n",
    "for i in range(EPOCHS):\n",
    "    \n",
    "    # Make some predictions using our basic model\n",
    "    preds = model(X)\n",
    "    \n",
    "    # compute the loss\n",
    "    loss = mse(preds, y)\n",
    "    \n",
    "    # print(\"MSE in epoch %d is %3.4f\" % (i,loss.item()),\"\\n\")\n",
    "    if (i+1) % 5 == 0:\n",
    "            print('Epoch [{}/{}], Loss: {:.4f}'.format(i+1, EPOCHS, loss.item()))\n",
    "\n",
    "    mse_list.append(loss.item())\n",
    "    \n",
    "    # compute gradients with respect to the weights and biases\n",
    "    loss.backward()\n",
    "    \n",
    "    # adjust the weights using a learning rate and reset gradients\n",
    "    with torch.no_grad():\n",
    "        w -= w.grad * learning_rate\n",
    "        b -= b.grad * learning_rate\n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_() \n",
    "        \n",
    "import matplotlib.pyplot as plt\n",
    "pd.Series(mse_list).plot()\n",
    "plt.xlabel(\"Epoch Number\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.title(\"MSE over Training EPOCHS\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "green-radar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss computation is: 0.79\n"
     ]
    }
   ],
   "source": [
    "# Calculate loss\n",
    "preds = model(X)\n",
    "loss = mse(preds, y)\n",
    "print(\"Final loss computation is:\",round(loss.item(),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approved-union",
   "metadata": {},
   "source": [
    "<h2>Linear Regression using PyTorch</h2>\n",
    "\n",
    "<img src=\"pics/spinning.png\" width =\"400\" height=400>\n",
    "\n",
    "We've implemented linear regression & gradient descent model using some basic tensor operations and we even used our own loss function. However, since this is a common pattern in deep learning, PyTorch provides several built-in functions and classes to make it easy to create and train models with just a few lines of code. **Let's be more trustful of PyTorch and use more of its considerable capabilites**. Keep in mind that what we are doing is along the following lines:\n",
    "\n",
    "1. Identify a target in our data and separate it from the predictors\n",
    "2. Perform any normalization (not always required)\n",
    "3. \"Tensorfy\" the X and y (target) structures\n",
    "4. Feed them into a Data Loader which simplifies the creation of batches\n",
    "5. Define an architecture for your model (e.g. layers, activation functions, dropouts)\n",
    "   - This will be a function of number of features \n",
    "   - Eventual output will match the unique values of your target\n",
    "6. Decide on a cost function (e.g. MSE) to minimize\n",
    "7. Pick an optimizer (e.g. SGD) to work in conjunction with number 5\n",
    "8. Pick a learning rate for number 6.\n",
    "\n",
    "Let's begin by importing the torch.nn package from PyTorch, which contains utility classes for building neural networks and ingesting data which simplifies downstream work. We'll use the **TensorDataset** function to help prep our X and y data from above. It's always a good idea to verify the type of data you have, specifically if it's already a tensor (nor not)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "dramatic-union",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X is of type <class 'torch.Tensor'>  and has shape torch.Size([20640, 6])\n",
      "y is of type <class 'torch.Tensor'>  and has shape torch.Size([20640, 1])\n"
     ]
    }
   ],
   "source": [
    "print(\"X is of type\",type(X),\" and has shape\",X.shape)\n",
    "print(\"y is of type\",type(X),\" and has shape\",y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "thirty-jewelry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Firs three rows and of X and y are: (tensor([[ 2.3448,  0.9821,  0.6286, -0.1538, -0.9744, -0.0496],\n",
      "        [ 2.3322, -0.6070,  0.3270, -0.2633,  0.8614, -0.0925],\n",
      "        [ 1.7827,  1.8562,  1.1556, -0.0490, -0.8208, -0.0258]]), tensor([[4.5260],\n",
      "        [3.5850],\n",
      "        [3.5210]]))\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "# Define dataset\n",
    "train_ds = TensorDataset(X, y)\n",
    "print(\"Firs three rows and of X and y are:\",train_ds[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scientific-maine",
   "metadata": {},
   "source": [
    "### Data Loaders\n",
    "\n",
    "One strength of PyTorch is its ability to manage very large data files which might require some for of subdivision to \"feed\" data into a network for efficient processing. While we could do this outselves it would be tedious. To this end, PyTorch has a class of utilities called **DataLoaders** which helps with this task.  \n",
    "\n",
    "In this case, the <b>DataLoader</b> function can take  a training dataset, (which itself has been prepared with **TensorDataset**) along with an indicated *batch_size*. We get back a series of X and y pairs, as tensors of course, which are then pushed into the network. When all batches have been processed we have completed one epoch. This includes foward and back propogation. And then for each subsequent epoch. we do it all again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "metallic-chess",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "# Define data loader\n",
    "batch_size = 1000\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solid-bottom",
   "metadata": {},
   "source": [
    "So the DataLoader operation will give is an iterable structure that provides batches of 1000 rows of data at a time which in this case that our model / network will consume approximately 21 batchs of 1000 rows each. 20460/1000. We could change this of course and use it a source of experimentation. When all batches have been through the network once, we call this an EPOCH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "impressed-caribbean",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of xb: torch.Size([1000, 6])\n",
      "Size if yb: torch.Size([1000, 1])\n"
     ]
    }
   ],
   "source": [
    "# Batch Loaders\n",
    "for xb, yb in train_dl:\n",
    "    print(\"Size of xb:\",xb.shape)\n",
    "    print(\"Size if yb:\",yb.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joint-curve",
   "metadata": {},
   "source": [
    "Next we can create a model which in this case is painfully simple. It's just a single Linear layer although this time we are actually using a PyTorch method. Remeber, in the previous example we used our set of equations (which was more or less a linear model).\n",
    "\n",
    "It's worth it to point out that here, I am using the **Functional** interace to PyTorch as opposed to the Object Oriented interface which is commonly used when processing images. In reality, either approach works. It becomes a matter of taste and common practice within one's domain. I find the Functional interface a little less verbose but this is up to you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "complimentary-burning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.3320, -0.4063, -0.0011,  0.0133, -0.0015,  0.0647]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.4070], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Define model - number of predictors is 6\n",
    "num_of_predictors = 6\n",
    "\n",
    "# This comes from PyTorch\n",
    "model = nn.Linear(num_of_predictors, 1)\n",
    "\n",
    "print(model.weight)\n",
    "print(model.bias)\n",
    "\n",
    "# Parameters\n",
    "list(model.parameters())\n",
    "\n",
    "# Import nn.functional\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define loss function - MSE\n",
    "loss_fn = F.mse_loss\n",
    "\n",
    "#loss = loss_fn(model(X), y, reduction=\"none\")\n",
    "loss = loss_fn(model(X), y)\n",
    "#print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "billion-attribute",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100], Training Loss: 2.9595\n",
      "Epoch [10/100], Training Loss: 2.3396\n",
      "Epoch [15/100], Training Loss: 1.8167\n",
      "Epoch [20/100], Training Loss: 1.3399\n",
      "Epoch [25/100], Training Loss: 0.9588\n",
      "Epoch [30/100], Training Loss: 1.0017\n",
      "Epoch [35/100], Training Loss: 0.9662\n",
      "Epoch [40/100], Training Loss: 0.8087\n",
      "Epoch [45/100], Training Loss: 0.7685\n",
      "Epoch [50/100], Training Loss: 0.6659\n",
      "Epoch [55/100], Training Loss: 0.6852\n",
      "Epoch [60/100], Training Loss: 0.6666\n",
      "Epoch [65/100], Training Loss: 0.7278\n",
      "Epoch [70/100], Training Loss: 0.6701\n",
      "Epoch [75/100], Training Loss: 0.5747\n",
      "Epoch [80/100], Training Loss: 0.6284\n",
      "Epoch [85/100], Training Loss: 0.6154\n",
      "Epoch [90/100], Training Loss: 0.6189\n",
      "Epoch [95/100], Training Loss: 0.5654\n",
      "Epoch [100/100], Training Loss: 0.5840\n"
     ]
    }
   ],
   "source": [
    "# So we also need an optimizer to work in conjunction with our\n",
    "# loss function. \n",
    "\n",
    "# Learning rate can impact this\n",
    "opt = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "# This a function desgined to process \n",
    "def fit(num_epochs, model, loss_fn, opt, train_dl):\n",
    "    \n",
    "    # Repeat for given number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        # Train with batches of data\n",
    "        for xb,yb in train_dl:\n",
    "            \n",
    "            # 1. Generate predictions\n",
    "            pred = model(xb)\n",
    "            \n",
    "            # 2. Calculate loss\n",
    "            loss = loss_fn(pred, yb)\n",
    "            \n",
    "            # 3. Compute gradients\n",
    "            loss.backward()\n",
    "            \n",
    "            # 4. Update parameters using gradients\n",
    "            opt.step()\n",
    "            \n",
    "            # 5. Reset the gradients to zero\n",
    "            opt.zero_grad()\n",
    "        \n",
    "        # Print the progress\n",
    "        if (epoch+1) % 5 == 0:\n",
    "            print('Epoch [{}/{}], Training Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
    "\n",
    "fit(100, model, loss_fn, opt, train_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "returning-receipt",
   "metadata": {},
   "source": [
    "## Things To Consider\n",
    "\n",
    "1. What impact does the learning rate have on this process ? \n",
    "2. How about the batch size ? \n",
    "3. Do the number of Epochs matter ? \n",
    "4. How about choice of optimizer ? \n",
    "5. What about creating a more sophisticated model architecture ?\n",
    "6. Have we learned anything about this model's applicability to unseen data ? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-alloy",
   "metadata": {},
   "source": [
    "<h2> Another Look At All of This </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-smoke",
   "metadata": {},
   "source": [
    "Okay, we've walked through the process of regression with a progressive immersion into the PyTorch way of doing things. This has been instructive but perhaps we should look at a more integrated example that more or less pulls it all together. There are also a few things we could do to make things more interesting:\n",
    "\n",
    "* A more sophisticated model architecture\n",
    "* Try the model on test / holdout data\n",
    "* Experiment with the learning rate and batch sizes\n",
    "\n",
    "There are other things we could try in addition to these but this is plenty for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "nonprofit-hazard",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intelligent-constant",
   "metadata": {},
   "source": [
    "We'll stick with the California data but let's read it in using a different approach so you can see how scikit-learn provides a convenient way to access a number of datasets. We will also attempt to carve off the first N number of records from the data to reserve for later use as a test data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "abandoned-shift",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16640, 1])\n",
      "torch.Size([16640, 1])\n"
     ]
    }
   ],
   "source": [
    "numtoholdout = 4000\n",
    "# Here we'll fetch the California and pull out the first \n",
    "# some number of rows as a test set\n",
    "\n",
    "# This fetches the X and y data\n",
    "(Xc,yc) = fetch_california_housing(return_X_y=True)\n",
    "\n",
    "# Now create a holdout / test set\n",
    "Xhold = Xc[0:numtoholdout,]\n",
    "yhold = yc[0:numtoholdout,]\n",
    "\n",
    "# Create the training data\n",
    "Xc = Xc[:-numtoholdout]\n",
    "yc = yc[:-numtoholdout]\n",
    "\n",
    "# Turn numpy structures into tensors\n",
    "y = torch.tensor(yc,dtype=torch.float)\n",
    "y = torch.unsqueeze(y,dim=1)\n",
    "#\n",
    "x = torch.tensor(Xc[:,0],dtype=torch.float)\n",
    "x = torch.unsqueeze(x,dim=1)\n",
    "#\n",
    "print(y.size())\n",
    "print(x.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "alive-public",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same for the holdout\n",
    "yt = torch.tensor(yhold,dtype=torch.float)\n",
    "yt = torch.unsqueeze(yt,dim=1)\n",
    "xt = torch.tensor(Xhold[:,0],dtype=torch.float)\n",
    "xt = torch.unsqueeze(xt,dim=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "included-imagination",
   "metadata": {},
   "source": [
    "Let's define a Sequential network that will contain more than just a single layer. We can experiment with this in any number of ways and you should feel free to do so. Many times there is not \"right\" architecture although the research in your domain of interest will frequently point to certain combinations of layers and whether to use drop puts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "lined-greensboro",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = 200\n",
    "net = torch.nn.Sequential(\n",
    "#        torch.nn.Dropout(),\n",
    "        torch.nn.Linear(1, layers),\n",
    "        torch.nn.LeakyReLU(),\n",
    "        torch.nn.Linear(layers, 100),\n",
    "        torch.nn.LeakyReLU(),\n",
    "        torch.nn.Linear(100, 1),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "speaking-fundamentals",
   "metadata": {},
   "source": [
    "Let's look at a different optimizer which in this case is Adam. We'll stick with MSE as our loss / cost function. Let's work in batches of 2000 over the course of 150 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "addressed-outline",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.00001)\n",
    "loss_func = torch.nn.MSELoss()  # this is for regression mean squared loss\n",
    "\n",
    "BATCH_SIZE = 2000\n",
    "EPOCH = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "occasional-referral",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_dataset = Data.TensorDataset(x, y)\n",
    "\n",
    "loader = Data.DataLoader(\n",
    "    dataset=torch_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "#    shuffle=True, num_workers=2,)\n",
    "    shuffle=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "answering-smart",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/150], Train Loss: 5.4329, Test Loss: 3.5938\n",
      "Epoch [10/150], Train Loss: 4.4658, Test Loss: 2.8413\n",
      "Epoch [15/150], Train Loss: 3.6584, Test Loss: 2.2290\n",
      "Epoch [20/150], Train Loss: 2.9211, Test Loss: 1.6891\n",
      "Epoch [25/150], Train Loss: 2.2883, Test Loss: 1.2309\n",
      "Epoch [30/150], Train Loss: 1.7819, Test Loss: 0.8930\n",
      "Epoch [35/150], Train Loss: 1.3812, Test Loss: 0.6471\n",
      "Epoch [40/150], Train Loss: 1.1460, Test Loss: 0.5080\n",
      "Epoch [45/150], Train Loss: 0.9595, Test Loss: 0.4329\n",
      "Epoch [50/150], Train Loss: 0.8683, Test Loss: 0.3965\n",
      "Epoch [55/150], Train Loss: 0.7971, Test Loss: 0.3874\n",
      "Epoch [60/150], Train Loss: 0.7600, Test Loss: 0.3931\n",
      "Epoch [65/150], Train Loss: 0.7308, Test Loss: 0.4045\n",
      "Epoch [70/150], Train Loss: 0.7235, Test Loss: 0.4167\n",
      "Epoch [75/150], Train Loss: 0.7238, Test Loss: 0.4278\n",
      "Epoch [80/150], Train Loss: 0.7281, Test Loss: 0.4366\n",
      "Epoch [85/150], Train Loss: 0.7143, Test Loss: 0.4432\n",
      "Epoch [90/150], Train Loss: 0.7133, Test Loss: 0.4478\n",
      "Epoch [95/150], Train Loss: 0.7126, Test Loss: 0.4510\n",
      "Epoch [100/150], Train Loss: 0.7234, Test Loss: 0.4538\n",
      "Epoch [105/150], Train Loss: 0.7107, Test Loss: 0.4590\n",
      "Epoch [110/150], Train Loss: 0.7184, Test Loss: 0.4599\n",
      "Epoch [115/150], Train Loss: 0.7118, Test Loss: 0.4604\n",
      "Epoch [120/150], Train Loss: 0.7158, Test Loss: 0.4607\n",
      "Epoch [125/150], Train Loss: 0.7176, Test Loss: 0.4620\n",
      "Epoch [130/150], Train Loss: 0.7183, Test Loss: 0.4621\n",
      "Epoch [135/150], Train Loss: 0.7015, Test Loss: 0.4627\n",
      "Epoch [140/150], Train Loss: 0.7099, Test Loss: 0.4629\n",
      "Epoch [145/150], Train Loss: 0.7096, Test Loss: 0.4634\n",
      "Epoch [150/150], Train Loss: 0.7053, Test Loss: 0.4642\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epoch')"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set up some accumulators for average training and test loss\n",
    "avloss = []\n",
    "avtestloss = []\n",
    "for epoch in range(EPOCH):\n",
    "    acc_loss = []\n",
    "    test_loss = []\n",
    "    for step, (batch_x, batch_y) in enumerate(loader): # for each training ste\n",
    "        \n",
    "        # the Variable function is a wrapper\n",
    "        # for tensor objects\n",
    "        \n",
    "#        b_x = Variable(batch_x)\n",
    "#        b_y = Variable(batch_y)\n",
    "        b_x = batch_x\n",
    "        b_y = batch_y\n",
    "\n",
    "        # Get the training loss per batch\n",
    "        prediction = net(b_x)     # input x and predict based on x\n",
    "        loss = loss_func(prediction, b_y)     # must be (1. nn output, 2. target)\n",
    "        acc_loss.append(loss.item())\n",
    "        \n",
    "        # Get the test loss per batch\n",
    "        testpred = net(xt)\n",
    "        predloss = loss_func(testpred,yt)\n",
    "        test_loss.append(predloss.item())\n",
    "\n",
    "        optimizer.zero_grad()   # clear gradients for next train\n",
    "        loss.backward()         # backpropagation, compute gradients\n",
    "        optimizer.step()        # apply gradients\n",
    "        \n",
    "        # print(\"Epoch %d: Train Loss %6.4f, Test Loss %6.4f\" % (epoch,np.mean(acc_loss),np.mean(test_loss)))\n",
    "    \n",
    "    avloss.append(np.mean(acc_loss))\n",
    "    avtestloss.append(np.mean(test_loss))\n",
    "    \n",
    "    if (epoch+1) % 5 == 0:\n",
    "        print('Epoch [{}/{}], Train Loss: {:.4f}, Test Loss: {:.4f}'.format(epoch+1, EPOCH, np.mean(acc_loss),np.mean(test_loss)))\n",
    "\n",
    "d = {'TrainLoss':avloss,'TestLoss':avtestloss}\n",
    "errdf = pd.DataFrame(d)\n",
    "\n",
    "errdf.plot.line()\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.title(\"Training / Test Loss\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-martial",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
